{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"knn_v2.ipynb","provenance":[{"file_id":"1nG1HkybMNli1gEE-c8zYI9KCaNIbm8AC","timestamp":1623296431873}],"collapsed_sections":[],"mount_file_id":"1Hpk-jAZ-lAEUSH0cwTXE8bqBe0DwcrfA","authorship_tag":"ABX9TyOrSmrylhR5b4fXsg3nlEVc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"0N7oMTbOgziO","executionInfo":{"status":"ok","timestamp":1623319148130,"user_tz":240,"elapsed":254,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"0f30b56c-763b-4086-8a9b-519920ffb09b"},"source":["import os\n","os.getcwd()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"ipdfkICcg3ek","executionInfo":{"status":"ok","timestamp":1623319148364,"user_tz":240,"elapsed":6,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["os.chdir('/content/drive/MyDrive/DINO')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_te9wXlhSiZ","executionInfo":{"status":"ok","timestamp":1623319149830,"user_tz":240,"elapsed":1471,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["import torch\n","from torch import nn\n","import torch.distributed as dist\n","import torch.backends.cudnn as cudnn\n","from torchvision import datasets\n","from torchvision import transforms as pth_transforms\n","\n","import numpy as np\n","\n","import utils\n","import vision_transformer as vits"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mP3Awpxxlw3I","executionInfo":{"status":"ok","timestamp":1623319149833,"user_tz":240,"elapsed":7,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, images, labels=None, transforms=None):\n","        self.X = images\n","        self.y = labels\n","        self.transforms = transforms\n","         \n","    def __len__(self):\n","        return (len(self.X))\n","    \n","    def __getitem__(self, i):\n","        data = self.X[i]\n","        #print(data.shape)\n","        data = np.asarray(data).astype(np.float32)\n","        #data = np.asarray(data).astype(np.uint8).reshape(28, 28, 1)\n","        \n","        if self.transforms:\n","            data = self.transforms(data)\n","            \n","        if self.y is not None:\n","            return (data, self.y[i])\n","        else:\n","            return data"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cDJv-XbKhVi5","executionInfo":{"status":"ok","timestamp":1623319183050,"user_tz":240,"elapsed":493,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["def extract_feature_pipeline(args):\n","    # ============ preparing data ... ============\n","    train_dataset = datasets.FashionMNIST(args.data_path, download=True, train=True)\n","    val_dataset = datasets.FashionMNIST(args.data_path, download=True, train=False)\n","    X_train = torch.flatten(train_dataset.data, start_dim=1).numpy()/255\n","    y_train = train_dataset.targets.numpy()\n","\n","    X_val = torch.flatten(val_dataset.data, start_dim=1).numpy()/255\n","    y_val = val_dataset.targets.numpy()\n","    dataset_train = CustomDataset(X_train, y_train)\n","    dataset_val = CustomDataset(X_val, y_val)\n","    sampler = torch.utils.data.DistributedSampler(dataset_train, shuffle=False)\n","    data_loader_train = torch.utils.data.DataLoader(\n","        dataset_train,\n","        sampler=sampler,\n","        batch_size=args.batch_size_per_gpu,\n","        num_workers=args.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","    data_loader_val = torch.utils.data.DataLoader(\n","        dataset_val,\n","        batch_size=args.batch_size_per_gpu,\n","        num_workers=args.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","    print(f\"Data loaded with {len(dataset_train)} train and {len(dataset_val)} val imgs.\")\n","\n","    # ============ building network ... ============\n","    model = vits.__dict__[args.arch](patch_size=args.patch_size, num_classes=0)\n","    print(f\"Model {args.arch} {args.patch_size}x{args.patch_size} built.\")\n","    model.cuda()\n","    utils.load_pretrained_weights(model, args.pretrained_weights, args.checkpoint_key, args.arch, args.patch_size)\n","    model.eval()\n","\n","    # ============ extract features ... ============\n","    print(\"Extracting features for train set...\")\n","    train_features = extract_features(model, data_loader_train)\n","    print(\"Extracting features for val set...\")\n","    test_features = extract_features(model, data_loader_val)\n","\n","    if utils.get_rank() == 0:\n","        train_features = nn.functional.normalize(train_features, dim=1, p=2)\n","        test_features = nn.functional.normalize(test_features, dim=1, p=2)\n","\n","    train_labels = torch.tensor([s for s in dataset_train.y]).long()\n","    test_labels = torch.tensor([s for s in dataset_val.y]).long()\n","    # save features and labels\n","    if args.dump_features and dist.get_rank() == 0:\n","        torch.save(train_features.cpu(), os.path.join(args.dump_features, \"trainfeat.pth\"))\n","        torch.save(test_features.cpu(), os.path.join(args.dump_features, \"testfeat.pth\"))\n","        torch.save(train_labels.cpu(), os.path.join(args.dump_features, \"trainlabels.pth\"))\n","        torch.save(test_labels.cpu(), os.path.join(args.dump_features, \"testlabels.pth\"))\n","    return train_features, test_features, train_labels, test_labels\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"FoIvstOuiWeM","executionInfo":{"status":"ok","timestamp":1623319186612,"user_tz":240,"elapsed":551,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["@torch.no_grad()\n","def extract_features(model, data_loader):\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    features = None\n","    for samples, index in metric_logger.log_every(data_loader, 10):\n","        samples = samples.cuda(non_blocking=True)\n","        index = index.cuda(non_blocking=True)\n","        feats = model(samples).clone()\n","\n","        # init storage feature matrix\n","        if dist.get_rank() == 0 and features is None:\n","            features = torch.zeros(len(data_loader.dataset), feats.shape[-1])\n","            if args.use_cuda:\n","                features = features.cuda(non_blocking=True)\n","            print(f\"Storing features into tensor of shape {features.shape}\")\n","\n","        # get indexes from all processes\n","        y_all = torch.empty(dist.get_world_size(), index.size(0), dtype=index.dtype, device=index.device)\n","        y_l = list(y_all.unbind(0))\n","        y_all_reduce = torch.distributed.all_gather(y_l, index, async_op=True)\n","        y_all_reduce.wait()\n","        index_all = torch.cat(y_l)\n","\n","        # share features between processes\n","        feats_all = torch.empty(\n","            dist.get_world_size(),\n","            feats.size(0),\n","            feats.size(1),\n","            dtype=feats.dtype,\n","            device=feats.device,\n","        )\n","        output_l = list(feats_all.unbind(0))\n","        output_all_reduce = torch.distributed.all_gather(output_l, feats, async_op=True)\n","        output_all_reduce.wait()\n","\n","        # update storage feature matrix\n","        if dist.get_rank() == 0:\n","            if args.use_cuda:\n","                features.index_copy_(0, index_all, torch.cat(output_l))\n","            else:\n","                features.index_copy_(0, index_all.cpu(), torch.cat(output_l).cpu())\n","    return features"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Re8wtY4ZikZK","executionInfo":{"status":"ok","timestamp":1623319189348,"user_tz":240,"elapsed":316,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["@torch.no_grad()\n","def knn_classifier(train_features, train_labels, test_features, test_labels, k, T, num_classes=10):\n","    top1, top5, total = 0.0, 0.0, 0\n","    train_features = train_features.t()\n","    num_test_images, num_chunks = test_labels.shape[0], 100\n","    imgs_per_chunk = num_test_images // num_chunks\n","    retrieval_one_hot = torch.zeros(k, num_classes).cuda()\n","    for idx in range(0, num_test_images, imgs_per_chunk):\n","        # get the features for test images\n","        features = test_features[\n","            idx : min((idx + imgs_per_chunk), num_test_images), :\n","        ]\n","        targets = test_labels[idx : min((idx + imgs_per_chunk), num_test_images)]\n","        batch_size = targets.shape[0]\n","\n","        # calculate the dot product and compute top-k neighbors\n","        similarity = torch.mm(features, train_features)\n","        distances, indices = similarity.topk(k, largest=True, sorted=True)\n","        candidates = train_labels.view(1, -1).expand(batch_size, -1)\n","        retrieved_neighbors = torch.gather(candidates, 1, indices)\n","\n","        retrieval_one_hot.resize_(batch_size * k, num_classes).zero_()\n","        retrieval_one_hot.scatter_(1, retrieved_neighbors.view(-1, 1), 1)\n","        distances_transform = distances.clone().div_(T).exp_()\n","        probs = torch.sum(\n","            torch.mul(\n","                retrieval_one_hot.view(batch_size, -1, num_classes),\n","                distances_transform.view(batch_size, -1, 1),\n","            ),\n","            1,\n","        )\n","        _, predictions = probs.sort(1, True)\n","\n","        # find the predictions that match the target\n","        correct = predictions.eq(targets.data.view(-1, 1))\n","        top1 = top1 + correct.narrow(1, 0, 1).sum().item()\n","        top5 = top5 + correct.narrow(1, 0, 5).sum().item()\n","        total += targets.size(0)\n","    top1 = top1 * 100.0 / total\n","    top5 = top5 * 100.0 / total\n","    return top1, top5"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvJNZLNBi_4c","executionInfo":{"status":"ok","timestamp":1623319192321,"user_tz":240,"elapsed":625,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["class ReturnIndexDataset(datasets.ImageFolder):\n","    def __getitem__(self, idx):\n","        img, lab = super(ReturnIndexDataset, self).__getitem__(idx)\n","        return img, idx"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"qgrwZAOAjsf9","executionInfo":{"status":"ok","timestamp":1623319195070,"user_tz":240,"elapsed":489,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './v2_result/checkpoint.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","\n","args=AttrDict(args)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yw5hoaKmjFfl","executionInfo":{"status":"ok","timestamp":1623319200477,"user_tz":240,"elapsed":3099,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"88014643-215e-46ee-fd24-d4b7019ede7a"},"source":["utils.init_distributed_mode(args)\n","print(\"git:\\n  {}\\n\".format(utils.get_sha()))\n","print(\"\\n\".join(\"%s: %s\" % (k, str(v)) for k, v in sorted(dict(vars(args)).items())))\n","cudnn.benchmark = True"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Will run the code on one GPU.\n","| distributed init (rank 0): env://\n","git:\n","  sha: N/A, status: clean, branch: N/A\n","\n","arch: vit_tiny\n","batch_size_per_gpu: 128\n","checkpoint_key: teacher\n","data_path: ./data/FashionMNIST\n","dist_url: env://\n","dump_features: None\n","gpu: 0\n","load_features: None\n","local_rank: 0\n","nb_knn: [10, 20, 100, 200]\n","num_workers: 10\n","patch_size: 4\n","pretrained_weights: ./v2_result/checkpoint.pth\n","rank: 0\n","temperature: 0.07\n","use_cuda: True\n","world_size: 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVgoZbvcjJJX","executionInfo":{"status":"ok","timestamp":1623319262714,"user_tz":240,"elapsed":60142,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"f95ba45f-58c6-4a14-88cb-755c0d250d8e"},"source":["if args.load_features:\n","    train_features = torch.load(os.path.join(args.load_features, \"trainfeat.pth\"))\n","    test_features = torch.load(os.path.join(args.load_features, \"testfeat.pth\"))\n","    train_labels = torch.load(os.path.join(args.load_features, \"trainlabels.pth\"))\n","    test_labels = torch.load(os.path.join(args.load_features, \"testlabels.pth\"))\n","else:\n","    # need to extract features !\n","    train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Data loaded with 60000 train and 10000 val imgs.\n","Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./v2_result/checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:38    time: 0.466789  data: 0.306990  max mem: 301\n","  [ 10/469]  eta: 0:00:49    time: 0.107609  data: 0.028171  max mem: 437\n","  [ 20/469]  eta: 0:00:48    time: 0.089080  data: 0.000241  max mem: 437\n","  [ 30/469]  eta: 0:00:46    time: 0.106399  data: 0.000319  max mem: 437\n","  [ 40/469]  eta: 0:00:45    time: 0.106367  data: 0.000329  max mem: 437\n","  [ 50/469]  eta: 0:00:44    time: 0.106360  data: 0.000204  max mem: 437\n","  [ 60/469]  eta: 0:00:43    time: 0.106310  data: 0.000200  max mem: 437\n","  [ 70/469]  eta: 0:00:42    time: 0.106381  data: 0.000210  max mem: 437\n","  [ 80/469]  eta: 0:00:41    time: 0.106408  data: 0.000211  max mem: 437\n","  [ 90/469]  eta: 0:00:40    time: 0.106367  data: 0.000223  max mem: 437\n","  [100/469]  eta: 0:00:39    time: 0.106354  data: 0.000230  max mem: 437\n","  [110/469]  eta: 0:00:38    time: 0.106346  data: 0.000234  max mem: 437\n","  [120/469]  eta: 0:00:37    time: 0.106345  data: 0.000236  max mem: 437\n","  [130/469]  eta: 0:00:36    time: 0.106313  data: 0.000219  max mem: 437\n","  [140/469]  eta: 0:00:35    time: 0.106363  data: 0.000214  max mem: 437\n","  [150/469]  eta: 0:00:33    time: 0.106440  data: 0.000213  max mem: 437\n","  [160/469]  eta: 0:00:32    time: 0.106396  data: 0.000203  max mem: 437\n","  [170/469]  eta: 0:00:31    time: 0.106384  data: 0.000195  max mem: 437\n","  [180/469]  eta: 0:00:30    time: 0.106389  data: 0.000205  max mem: 437\n","  [190/469]  eta: 0:00:29    time: 0.106365  data: 0.000169  max mem: 437\n","  [200/469]  eta: 0:00:28    time: 0.106360  data: 0.000158  max mem: 437\n","  [210/469]  eta: 0:00:27    time: 0.106414  data: 0.000187  max mem: 437\n","  [220/469]  eta: 0:00:26    time: 0.106466  data: 0.000182  max mem: 437\n","  [230/469]  eta: 0:00:25    time: 0.106394  data: 0.000186  max mem: 437\n","  [240/469]  eta: 0:00:24    time: 0.106349  data: 0.000164  max mem: 437\n","  [250/469]  eta: 0:00:23    time: 0.106371  data: 0.000168  max mem: 437\n","  [260/469]  eta: 0:00:22    time: 0.106415  data: 0.000200  max mem: 437\n","  [270/469]  eta: 0:00:21    time: 0.106401  data: 0.000209  max mem: 437\n","  [280/469]  eta: 0:00:20    time: 0.106348  data: 0.000214  max mem: 437\n","  [290/469]  eta: 0:00:19    time: 0.106395  data: 0.000188  max mem: 437\n","  [300/469]  eta: 0:00:17    time: 0.106400  data: 0.000170  max mem: 437\n","  [310/469]  eta: 0:00:16    time: 0.106391  data: 0.000284  max mem: 437\n","  [320/469]  eta: 0:00:15    time: 0.106409  data: 0.000331  max mem: 437\n","  [330/469]  eta: 0:00:14    time: 0.106324  data: 0.000228  max mem: 437\n","  [340/469]  eta: 0:00:13    time: 0.106348  data: 0.000225  max mem: 437\n","  [350/469]  eta: 0:00:12    time: 0.106417  data: 0.000363  max mem: 437\n","  [360/469]  eta: 0:00:11    time: 0.106359  data: 0.000465  max mem: 437\n","  [370/469]  eta: 0:00:10    time: 0.106297  data: 0.000442  max mem: 437\n","  [380/469]  eta: 0:00:09    time: 0.106327  data: 0.000274  max mem: 437\n","  [390/469]  eta: 0:00:08    time: 0.106343  data: 0.000129  max mem: 437\n","  [400/469]  eta: 0:00:07    time: 0.106353  data: 0.000188  max mem: 437\n","  [410/469]  eta: 0:00:06    time: 0.106417  data: 0.000232  max mem: 437\n","  [420/469]  eta: 0:00:05    time: 0.106443  data: 0.000220  max mem: 437\n","  [430/469]  eta: 0:00:04    time: 0.106452  data: 0.000375  max mem: 437\n","  [440/469]  eta: 0:00:03    time: 0.106409  data: 0.000377  max mem: 437\n","  [450/469]  eta: 0:00:02    time: 0.106349  data: 0.000259  max mem: 437\n","  [460/469]  eta: 0:00:00    time: 0.106385  data: 0.000231  max mem: 437\n","  [468/469]  eta: 0:00:00    time: 0.119817  data: 0.000166  max mem: 437\n"," Total time: 0:00:50 (0.107387 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:31    time: 0.397171  data: 0.282113  max mem: 437\n","  [10/79]  eta: 0:00:06    time: 0.101096  data: 0.025822  max mem: 484\n","  [20/79]  eta: 0:00:06    time: 0.089007  data: 0.000205  max mem: 484\n","  [30/79]  eta: 0:00:05    time: 0.106445  data: 0.000236  max mem: 484\n","  [40/79]  eta: 0:00:04    time: 0.106414  data: 0.000235  max mem: 484\n","  [50/79]  eta: 0:00:03    time: 0.106437  data: 0.000216  max mem: 484\n","  [60/79]  eta: 0:00:02    time: 0.106428  data: 0.000212  max mem: 484\n","  [70/79]  eta: 0:00:00    time: 0.106406  data: 0.000178  max mem: 484\n","  [78/79]  eta: 0:00:00    time: 0.120172  data: 0.000149  max mem: 484\n"," Total time: 0:00:08 (0.111167 s / it)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLS-Q-GiVo8J","executionInfo":{"status":"ok","timestamp":1623319267862,"user_tz":240,"elapsed":1413,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"bd91b4fa-1797-4d15-c236-3963c8863c5e"},"source":["if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.01, Top5: 50.0\n","20-NN classifier result: Top1: 10.01, Top5: 49.99\n","100-NN classifier result: Top1: 10.01, Top5: 49.98\n","200-NN classifier result: Top1: 9.98, Top5: 49.96\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WtAalfmyqA5-","executionInfo":{"status":"ok","timestamp":1623319874384,"user_tz":240,"elapsed":61623,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"e6a5cfa7-d3ea-412c-bcaf-2ec8e237c1fe"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './v2_result/checkpoint0000.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Data loaded with 60000 train and 10000 val imgs.\n","Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./v2_result/checkpoint0000.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:22    time: 0.431040  data: 0.283867  max mem: 484\n","  [ 10/469]  eta: 0:00:47    time: 0.104348  data: 0.026224  max mem: 484\n","  [ 20/469]  eta: 0:00:47    time: 0.089055  data: 0.000321  max mem: 484\n","  [ 30/469]  eta: 0:00:46    time: 0.106456  data: 0.000220  max mem: 484\n","  [ 40/469]  eta: 0:00:45    time: 0.106363  data: 0.000194  max mem: 484\n","  [ 50/469]  eta: 0:00:44    time: 0.106330  data: 0.000162  max mem: 484\n","  [ 60/469]  eta: 0:00:43    time: 0.106417  data: 0.000344  max mem: 484\n","  [ 70/469]  eta: 0:00:42    time: 0.106318  data: 0.000312  max mem: 484\n","  [ 80/469]  eta: 0:00:41    time: 0.106275  data: 0.000241  max mem: 484\n","  [ 90/469]  eta: 0:00:40    time: 0.106367  data: 0.000353  max mem: 484\n","  [100/469]  eta: 0:00:39    time: 0.106397  data: 0.000401  max mem: 484\n","  [110/469]  eta: 0:00:38    time: 0.106370  data: 0.000320  max mem: 484\n","  [120/469]  eta: 0:00:37    time: 0.106396  data: 0.000157  max mem: 484\n","  [130/469]  eta: 0:00:36    time: 0.106364  data: 0.000164  max mem: 484\n","  [140/469]  eta: 0:00:34    time: 0.106322  data: 0.000205  max mem: 484\n","  [150/469]  eta: 0:00:33    time: 0.106438  data: 0.000202  max mem: 484\n","  [160/469]  eta: 0:00:32    time: 0.106432  data: 0.000232  max mem: 484\n","  [170/469]  eta: 0:00:31    time: 0.106378  data: 0.000229  max mem: 484\n","  [180/469]  eta: 0:00:30    time: 0.106351  data: 0.000200  max mem: 484\n","  [190/469]  eta: 0:00:29    time: 0.106362  data: 0.000205  max mem: 484\n","  [200/469]  eta: 0:00:28    time: 0.106446  data: 0.000263  max mem: 484\n","  [210/469]  eta: 0:00:27    time: 0.106431  data: 0.000295  max mem: 484\n","  [220/469]  eta: 0:00:26    time: 0.106313  data: 0.000236  max mem: 484\n","  [230/469]  eta: 0:00:25    time: 0.106361  data: 0.000198  max mem: 484\n","  [240/469]  eta: 0:00:24    time: 0.106461  data: 0.000190  max mem: 484\n","  [250/469]  eta: 0:00:23    time: 0.106352  data: 0.000170  max mem: 484\n","  [260/469]  eta: 0:00:22    time: 0.106304  data: 0.000264  max mem: 484\n","  [270/469]  eta: 0:00:21    time: 0.106366  data: 0.000298  max mem: 484\n","  [280/469]  eta: 0:00:20    time: 0.106454  data: 0.000221  max mem: 484\n","  [290/469]  eta: 0:00:19    time: 0.106434  data: 0.000223  max mem: 484\n","  [300/469]  eta: 0:00:17    time: 0.106419  data: 0.000208  max mem: 484\n","  [310/469]  eta: 0:00:16    time: 0.106493  data: 0.000200  max mem: 484\n","  [320/469]  eta: 0:00:15    time: 0.106469  data: 0.000208  max mem: 484\n","  [330/469]  eta: 0:00:14    time: 0.106420  data: 0.000170  max mem: 484\n","  [340/469]  eta: 0:00:13    time: 0.106378  data: 0.000161  max mem: 484\n","  [350/469]  eta: 0:00:12    time: 0.106366  data: 0.000210  max mem: 490\n","  [360/469]  eta: 0:00:11    time: 0.106388  data: 0.000224  max mem: 490\n","  [370/469]  eta: 0:00:10    time: 0.106421  data: 0.000207  max mem: 490\n","  [380/469]  eta: 0:00:09    time: 0.106392  data: 0.000165  max mem: 490\n","  [390/469]  eta: 0:00:08    time: 0.106399  data: 0.000184  max mem: 490\n","  [400/469]  eta: 0:00:07    time: 0.106476  data: 0.000215  max mem: 490\n","  [410/469]  eta: 0:00:06    time: 0.106435  data: 0.000170  max mem: 490\n","  [420/469]  eta: 0:00:05    time: 0.106391  data: 0.000166  max mem: 490\n","  [430/469]  eta: 0:00:04    time: 0.106405  data: 0.000194  max mem: 490\n","  [440/469]  eta: 0:00:03    time: 0.106402  data: 0.000198  max mem: 490\n","  [450/469]  eta: 0:00:02    time: 0.106415  data: 0.000227  max mem: 490\n","  [460/469]  eta: 0:00:00    time: 0.106351  data: 0.000198  max mem: 490\n","  [468/469]  eta: 0:00:00    time: 0.106390  data: 0.000142  max mem: 490\n"," Total time: 0:00:50 (0.106752 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:30    time: 0.387293  data: 0.274143  max mem: 490\n","  [10/79]  eta: 0:00:06    time: 0.100108  data: 0.025080  max mem: 490\n","  [20/79]  eta: 0:00:06    time: 0.088903  data: 0.000176  max mem: 490\n","  [30/79]  eta: 0:00:05    time: 0.106423  data: 0.000192  max mem: 490\n","  [40/79]  eta: 0:00:04    time: 0.106385  data: 0.000176  max mem: 490\n","  [50/79]  eta: 0:00:03    time: 0.106382  data: 0.000170  max mem: 490\n","  [60/79]  eta: 0:00:02    time: 0.106443  data: 0.000156  max mem: 490\n","  [70/79]  eta: 0:00:00    time: 0.106458  data: 0.000096  max mem: 490\n","  [78/79]  eta: 0:00:00    time: 0.106408  data: 0.000108  max mem: 490\n"," Total time: 0:00:08 (0.107600 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.0, Top5: 50.0\n","20-NN classifier result: Top1: 10.0, Top5: 49.99\n","100-NN classifier result: Top1: 10.0, Top5: 49.98\n","200-NN classifier result: Top1: 9.97, Top5: 49.96\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIGHju6HqF9j","executionInfo":{"status":"ok","timestamp":1623319935624,"user_tz":240,"elapsed":61245,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"b52e65c5-a7aa-47b5-f113-0b7207de7067"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './v2_result/checkpoint0005.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Data loaded with 60000 train and 10000 val imgs.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./v2_result/checkpoint0005.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:22    time: 0.432280  data: 0.297773  max mem: 490\n","  [ 10/469]  eta: 0:00:47    time: 0.104306  data: 0.027230  max mem: 490\n","  [ 20/469]  eta: 0:00:47    time: 0.088928  data: 0.000202  max mem: 490\n","  [ 30/469]  eta: 0:00:46    time: 0.106388  data: 0.000228  max mem: 490\n","  [ 40/469]  eta: 0:00:45    time: 0.106409  data: 0.000220  max mem: 490\n","  [ 50/469]  eta: 0:00:44    time: 0.106449  data: 0.000202  max mem: 490\n","  [ 60/469]  eta: 0:00:43    time: 0.106480  data: 0.000183  max mem: 490\n","  [ 70/469]  eta: 0:00:42    time: 0.106438  data: 0.000169  max mem: 490\n","  [ 80/469]  eta: 0:00:41    time: 0.106429  data: 0.000180  max mem: 490\n","  [ 90/469]  eta: 0:00:40    time: 0.106466  data: 0.000202  max mem: 490\n","  [100/469]  eta: 0:00:39    time: 0.106443  data: 0.000177  max mem: 490\n","  [110/469]  eta: 0:00:38    time: 0.106417  data: 0.000167  max mem: 490\n","  [120/469]  eta: 0:00:37    time: 0.106450  data: 0.000185  max mem: 490\n","  [130/469]  eta: 0:00:36    time: 0.106492  data: 0.000191  max mem: 490\n","  [140/469]  eta: 0:00:34    time: 0.106512  data: 0.000193  max mem: 490\n","  [150/469]  eta: 0:00:33    time: 0.106490  data: 0.000192  max mem: 490\n","  [160/469]  eta: 0:00:32    time: 0.106456  data: 0.000199  max mem: 490\n","  [170/469]  eta: 0:00:31    time: 0.106454  data: 0.000196  max mem: 490\n","  [180/469]  eta: 0:00:30    time: 0.106480  data: 0.000202  max mem: 490\n","  [190/469]  eta: 0:00:29    time: 0.106465  data: 0.000195  max mem: 490\n","  [200/469]  eta: 0:00:28    time: 0.106478  data: 0.000202  max mem: 490\n","  [210/469]  eta: 0:00:27    time: 0.106493  data: 0.000218  max mem: 490\n","  [220/469]  eta: 0:00:26    time: 0.106461  data: 0.000210  max mem: 490\n","  [230/469]  eta: 0:00:25    time: 0.106447  data: 0.000199  max mem: 490\n","  [240/469]  eta: 0:00:24    time: 0.106471  data: 0.000358  max mem: 490\n","  [250/469]  eta: 0:00:23    time: 0.106486  data: 0.000374  max mem: 490\n","  [260/469]  eta: 0:00:22    time: 0.106477  data: 0.000223  max mem: 490\n","  [270/469]  eta: 0:00:21    time: 0.106478  data: 0.000207  max mem: 490\n","  [280/469]  eta: 0:00:20    time: 0.106466  data: 0.000196  max mem: 490\n","  [290/469]  eta: 0:00:19    time: 0.106453  data: 0.000213  max mem: 490\n","  [300/469]  eta: 0:00:17    time: 0.106474  data: 0.000208  max mem: 490\n","  [310/469]  eta: 0:00:16    time: 0.106490  data: 0.000209  max mem: 490\n","  [320/469]  eta: 0:00:15    time: 0.106456  data: 0.000225  max mem: 490\n","  [330/469]  eta: 0:00:14    time: 0.106380  data: 0.000413  max mem: 490\n","  [340/469]  eta: 0:00:13    time: 0.106396  data: 0.000414  max mem: 490\n","  [350/469]  eta: 0:00:12    time: 0.106454  data: 0.000223  max mem: 490\n","  [360/469]  eta: 0:00:11    time: 0.106459  data: 0.000231  max mem: 490\n","  [370/469]  eta: 0:00:10    time: 0.106464  data: 0.000225  max mem: 490\n","  [380/469]  eta: 0:00:09    time: 0.106404  data: 0.000252  max mem: 490\n","  [390/469]  eta: 0:00:08    time: 0.106434  data: 0.000256  max mem: 490\n","  [400/469]  eta: 0:00:07    time: 0.106495  data: 0.000220  max mem: 490\n","  [410/469]  eta: 0:00:06    time: 0.106462  data: 0.000231  max mem: 490\n","  [420/469]  eta: 0:00:05    time: 0.106442  data: 0.000234  max mem: 490\n","  [430/469]  eta: 0:00:04    time: 0.106426  data: 0.000225  max mem: 490\n","  [440/469]  eta: 0:00:03    time: 0.106461  data: 0.000344  max mem: 490\n","  [450/469]  eta: 0:00:02    time: 0.106492  data: 0.000360  max mem: 490\n","  [460/469]  eta: 0:00:00    time: 0.106432  data: 0.000209  max mem: 490\n","  [468/469]  eta: 0:00:00    time: 0.106441  data: 0.000163  max mem: 490\n"," Total time: 0:00:50 (0.106795 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:32    time: 0.408024  data: 0.281549  max mem: 490\n","  [10/79]  eta: 0:00:07    time: 0.101999  data: 0.025761  max mem: 490\n","  [20/79]  eta: 0:00:06    time: 0.088912  data: 0.000186  max mem: 490\n","  [30/79]  eta: 0:00:05    time: 0.106444  data: 0.000212  max mem: 490\n","  [40/79]  eta: 0:00:04    time: 0.106387  data: 0.000220  max mem: 490\n","  [50/79]  eta: 0:00:03    time: 0.106335  data: 0.000218  max mem: 490\n","  [60/79]  eta: 0:00:02    time: 0.106383  data: 0.000237  max mem: 490\n","  [70/79]  eta: 0:00:00    time: 0.106385  data: 0.000172  max mem: 490\n","  [78/79]  eta: 0:00:00    time: 0.106395  data: 0.000133  max mem: 490\n"," Total time: 0:00:08 (0.107849 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.01, Top5: 50.01\n","20-NN classifier result: Top1: 10.01, Top5: 50.0\n","100-NN classifier result: Top1: 10.01, Top5: 49.99\n","200-NN classifier result: Top1: 9.98, Top5: 49.98\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyPaQuYSqG_6","executionInfo":{"status":"ok","timestamp":1623319998311,"user_tz":240,"elapsed":61850,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"853fc85f-1160-4032-e804-be8ac090be63"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './v2_result/checkpoint0010.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Data loaded with 60000 train and 10000 val imgs.\n","Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./v2_result/checkpoint0010.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:32    time: 0.452466  data: 0.320707  max mem: 490\n","  [ 10/469]  eta: 0:00:49    time: 0.107100  data: 0.029358  max mem: 490\n","  [ 20/469]  eta: 0:00:47    time: 0.089511  data: 0.000216  max mem: 490\n","  [ 30/469]  eta: 0:00:46    time: 0.106498  data: 0.000214  max mem: 490\n","  [ 40/469]  eta: 0:00:45    time: 0.106527  data: 0.000219  max mem: 490\n","  [ 50/469]  eta: 0:00:44    time: 0.106493  data: 0.000315  max mem: 490\n","  [ 60/469]  eta: 0:00:43    time: 0.106457  data: 0.000309  max mem: 490\n","  [ 70/469]  eta: 0:00:42    time: 0.106388  data: 0.000213  max mem: 490\n","  [ 80/469]  eta: 0:00:41    time: 0.106400  data: 0.000216  max mem: 490\n","  [ 90/469]  eta: 0:00:40    time: 0.106440  data: 0.000211  max mem: 490\n","  [100/469]  eta: 0:00:39    time: 0.106409  data: 0.000396  max mem: 490\n","  [110/469]  eta: 0:00:38    time: 0.106418  data: 0.000393  max mem: 490\n","  [120/469]  eta: 0:00:37    time: 0.106476  data: 0.000215  max mem: 490\n","  [130/469]  eta: 0:00:36    time: 0.106510  data: 0.000216  max mem: 490\n","  [140/469]  eta: 0:00:35    time: 0.106466  data: 0.000219  max mem: 490\n","  [150/469]  eta: 0:00:33    time: 0.106451  data: 0.000220  max mem: 490\n","  [160/469]  eta: 0:00:32    time: 0.106498  data: 0.000230  max mem: 490\n","  [170/469]  eta: 0:00:31    time: 0.106482  data: 0.000241  max mem: 490\n","  [180/469]  eta: 0:00:30    time: 0.106450  data: 0.000233  max mem: 490\n","  [190/469]  eta: 0:00:29    time: 0.106462  data: 0.000248  max mem: 490\n","  [200/469]  eta: 0:00:28    time: 0.106466  data: 0.000262  max mem: 490\n","  [210/469]  eta: 0:00:27    time: 0.106413  data: 0.000233  max mem: 490\n","  [220/469]  eta: 0:00:26    time: 0.106389  data: 0.000211  max mem: 490\n","  [230/469]  eta: 0:00:25    time: 0.106381  data: 0.000178  max mem: 490\n","  [240/469]  eta: 0:00:24    time: 0.106403  data: 0.000181  max mem: 490\n","  [250/469]  eta: 0:00:23    time: 0.106454  data: 0.000215  max mem: 490\n","  [260/469]  eta: 0:00:22    time: 0.106460  data: 0.000213  max mem: 490\n","  [270/469]  eta: 0:00:21    time: 0.106502  data: 0.000221  max mem: 490\n","  [280/469]  eta: 0:00:20    time: 0.106525  data: 0.000230  max mem: 490\n","  [290/469]  eta: 0:00:19    time: 0.106479  data: 0.000228  max mem: 490\n","  [300/469]  eta: 0:00:17    time: 0.106445  data: 0.000177  max mem: 490\n","  [310/469]  eta: 0:00:16    time: 0.106470  data: 0.000161  max mem: 490\n","  [320/469]  eta: 0:00:15    time: 0.106486  data: 0.000195  max mem: 490\n","  [330/469]  eta: 0:00:14    time: 0.106458  data: 0.000196  max mem: 490\n","  [340/469]  eta: 0:00:13    time: 0.106441  data: 0.000194  max mem: 490\n","  [350/469]  eta: 0:00:12    time: 0.106483  data: 0.000168  max mem: 490\n","  [360/469]  eta: 0:00:11    time: 0.106518  data: 0.000276  max mem: 490\n","  [370/469]  eta: 0:00:10    time: 0.106496  data: 0.000312  max mem: 490\n","  [380/469]  eta: 0:00:09    time: 0.106430  data: 0.000208  max mem: 490\n","  [390/469]  eta: 0:00:08    time: 0.106403  data: 0.000208  max mem: 490\n","  [400/469]  eta: 0:00:07    time: 0.106457  data: 0.000224  max mem: 490\n","  [410/469]  eta: 0:00:06    time: 0.106476  data: 0.000192  max mem: 490\n","  [420/469]  eta: 0:00:05    time: 0.106447  data: 0.000179  max mem: 490\n","  [430/469]  eta: 0:00:04    time: 0.106427  data: 0.000223  max mem: 490\n","  [440/469]  eta: 0:00:03    time: 0.106451  data: 0.000234  max mem: 490\n","  [450/469]  eta: 0:00:02    time: 0.106480  data: 0.000267  max mem: 490\n","  [460/469]  eta: 0:00:00    time: 0.106484  data: 0.000227  max mem: 490\n","  [468/469]  eta: 0:00:00    time: 0.106462  data: 0.000155  max mem: 490\n"," Total time: 0:00:50 (0.106867 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:32    time: 0.410878  data: 0.297573  max mem: 490\n","  [10/79]  eta: 0:00:07    time: 0.102265  data: 0.027180  max mem: 490\n","  [20/79]  eta: 0:00:06    time: 0.088919  data: 0.000174  max mem: 490\n","  [30/79]  eta: 0:00:05    time: 0.106438  data: 0.000216  max mem: 490\n","  [40/79]  eta: 0:00:04    time: 0.106430  data: 0.000179  max mem: 497\n","  [50/79]  eta: 0:00:03    time: 0.106431  data: 0.000161  max mem: 497\n","  [60/79]  eta: 0:00:02    time: 0.106411  data: 0.000153  max mem: 497\n","  [70/79]  eta: 0:00:00    time: 0.106379  data: 0.000132  max mem: 497\n","  [78/79]  eta: 0:00:00    time: 0.106404  data: 0.000150  max mem: 497\n"," Total time: 0:00:08 (0.107851 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.0, Top5: 50.0\n","20-NN classifier result: Top1: 10.0, Top5: 49.99\n","100-NN classifier result: Top1: 10.0, Top5: 49.98\n","200-NN classifier result: Top1: 9.97, Top5: 49.97\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U2FQIkVJDLHp","executionInfo":{"status":"ok","timestamp":1623320059454,"user_tz":240,"elapsed":61148,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"61690947-fce5-41a7-9f8a-205e15298aca"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './v2_result/checkpoint0015.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Data loaded with 60000 train and 10000 val imgs.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./v2_result/checkpoint0015.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:14    time: 0.414796  data: 0.292536  max mem: 497\n","  [ 10/469]  eta: 0:00:47    time: 0.102685  data: 0.026764  max mem: 497\n","  [ 20/469]  eta: 0:00:46    time: 0.088970  data: 0.000171  max mem: 497\n","  [ 30/469]  eta: 0:00:46    time: 0.106415  data: 0.000242  max mem: 497\n","  [ 40/469]  eta: 0:00:45    time: 0.106370  data: 0.000249  max mem: 497\n","  [ 50/469]  eta: 0:00:44    time: 0.106420  data: 0.000207  max mem: 497\n","  [ 60/469]  eta: 0:00:43    time: 0.106432  data: 0.000225  max mem: 497\n","  [ 70/469]  eta: 0:00:42    time: 0.106463  data: 0.000205  max mem: 497\n","  [ 80/469]  eta: 0:00:41    time: 0.106494  data: 0.000202  max mem: 497\n","  [ 90/469]  eta: 0:00:40    time: 0.106423  data: 0.000309  max mem: 497\n","  [100/469]  eta: 0:00:39    time: 0.106445  data: 0.000304  max mem: 497\n","  [110/469]  eta: 0:00:38    time: 0.106479  data: 0.000209  max mem: 497\n","  [120/469]  eta: 0:00:37    time: 0.106468  data: 0.000237  max mem: 497\n","  [130/469]  eta: 0:00:35    time: 0.106491  data: 0.000250  max mem: 497\n","  [140/469]  eta: 0:00:34    time: 0.106486  data: 0.000345  max mem: 497\n","  [150/469]  eta: 0:00:33    time: 0.106464  data: 0.000330  max mem: 497\n","  [160/469]  eta: 0:00:32    time: 0.106473  data: 0.000220  max mem: 497\n","  [170/469]  eta: 0:00:31    time: 0.106479  data: 0.000215  max mem: 497\n","  [180/469]  eta: 0:00:30    time: 0.106453  data: 0.000210  max mem: 497\n","  [190/469]  eta: 0:00:29    time: 0.106485  data: 0.000194  max mem: 497\n","  [200/469]  eta: 0:00:28    time: 0.106505  data: 0.000314  max mem: 497\n","  [210/469]  eta: 0:00:27    time: 0.106450  data: 0.000465  max mem: 497\n","  [220/469]  eta: 0:00:26    time: 0.106457  data: 0.000340  max mem: 497\n","  [230/469]  eta: 0:00:25    time: 0.106483  data: 0.000201  max mem: 497\n","  [240/469]  eta: 0:00:24    time: 0.106491  data: 0.000201  max mem: 497\n","  [250/469]  eta: 0:00:23    time: 0.106457  data: 0.000198  max mem: 497\n","  [260/469]  eta: 0:00:22    time: 0.106453  data: 0.000196  max mem: 497\n","  [270/469]  eta: 0:00:21    time: 0.106505  data: 0.000195  max mem: 497\n","  [280/469]  eta: 0:00:20    time: 0.106489  data: 0.000319  max mem: 497\n","  [290/469]  eta: 0:00:19    time: 0.106470  data: 0.000333  max mem: 497\n","  [300/469]  eta: 0:00:17    time: 0.106462  data: 0.000218  max mem: 497\n","  [310/469]  eta: 0:00:16    time: 0.106473  data: 0.000201  max mem: 497\n","  [320/469]  eta: 0:00:15    time: 0.106499  data: 0.000198  max mem: 497\n","  [330/469]  eta: 0:00:14    time: 0.106469  data: 0.000207  max mem: 497\n","  [340/469]  eta: 0:00:13    time: 0.106435  data: 0.000208  max mem: 497\n","  [350/469]  eta: 0:00:12    time: 0.106486  data: 0.000189  max mem: 497\n","  [360/469]  eta: 0:00:11    time: 0.106549  data: 0.000185  max mem: 497\n","  [370/469]  eta: 0:00:10    time: 0.106506  data: 0.000209  max mem: 497\n","  [380/469]  eta: 0:00:09    time: 0.106464  data: 0.000227  max mem: 497\n","  [390/469]  eta: 0:00:08    time: 0.106475  data: 0.000222  max mem: 497\n","  [400/469]  eta: 0:00:07    time: 0.106468  data: 0.000234  max mem: 497\n","  [410/469]  eta: 0:00:06    time: 0.106483  data: 0.000228  max mem: 497\n","  [420/469]  eta: 0:00:05    time: 0.106487  data: 0.000201  max mem: 497\n","  [430/469]  eta: 0:00:04    time: 0.106479  data: 0.000196  max mem: 497\n","  [440/469]  eta: 0:00:03    time: 0.106480  data: 0.000202  max mem: 528\n","  [450/469]  eta: 0:00:02    time: 0.106456  data: 0.000253  max mem: 528\n","  [460/469]  eta: 0:00:00    time: 0.106436  data: 0.000226  max mem: 528\n","  [468/469]  eta: 0:00:00    time: 0.106449  data: 0.000166  max mem: 528\n"," Total time: 0:00:50 (0.106779 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:32    time: 0.405637  data: 0.280647  max mem: 528\n","  [10/79]  eta: 0:00:07    time: 0.101894  data: 0.025675  max mem: 528\n","  [20/79]  eta: 0:00:06    time: 0.088943  data: 0.000193  max mem: 528\n","  [30/79]  eta: 0:00:05    time: 0.106440  data: 0.000215  max mem: 528\n","  [40/79]  eta: 0:00:04    time: 0.106495  data: 0.000226  max mem: 528\n","  [50/79]  eta: 0:00:03    time: 0.106452  data: 0.000192  max mem: 528\n","  [60/79]  eta: 0:00:02    time: 0.106448  data: 0.000175  max mem: 528\n","  [70/79]  eta: 0:00:00    time: 0.106492  data: 0.000147  max mem: 528\n","  [78/79]  eta: 0:00:00    time: 0.106443  data: 0.000125  max mem: 528\n"," Total time: 0:00:08 (0.107935 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.01, Top5: 50.01\n","20-NN classifier result: Top1: 10.01, Top5: 50.0\n","100-NN classifier result: Top1: 10.01, Top5: 49.99\n","200-NN classifier result: Top1: 9.98, Top5: 49.98\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yxq11iJhjglM","executionInfo":{"status":"ok","timestamp":1623320121877,"user_tz":240,"elapsed":61625,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"627b93da-47c8-4ff4-a285-7bd3aaa5dbff"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './v2_result/checkpoint0075.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": \"./v2_result/knn\", \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Data loaded with 60000 train and 10000 val imgs.\n","Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./v2_result/checkpoint0075.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:19    time: 0.424999  data: 0.290554  max mem: 528\n","  [ 10/469]  eta: 0:00:47    time: 0.103715  data: 0.026549  max mem: 528\n","  [ 20/469]  eta: 0:00:47    time: 0.089049  data: 0.000168  max mem: 528\n","  [ 30/469]  eta: 0:00:46    time: 0.106445  data: 0.000204  max mem: 528\n","  [ 40/469]  eta: 0:00:45    time: 0.106431  data: 0.000208  max mem: 528\n","  [ 50/469]  eta: 0:00:44    time: 0.106498  data: 0.000333  max mem: 528\n","  [ 60/469]  eta: 0:00:43    time: 0.106478  data: 0.000335  max mem: 528\n","  [ 70/469]  eta: 0:00:42    time: 0.106441  data: 0.000200  max mem: 528\n","  [ 80/469]  eta: 0:00:41    time: 0.106445  data: 0.000321  max mem: 528\n","  [ 90/469]  eta: 0:00:40    time: 0.106469  data: 0.000324  max mem: 528\n","  [100/469]  eta: 0:00:39    time: 0.106454  data: 0.000206  max mem: 528\n","  [110/469]  eta: 0:00:38    time: 0.106463  data: 0.000222  max mem: 528\n","  [120/469]  eta: 0:00:37    time: 0.106500  data: 0.000216  max mem: 528\n","  [130/469]  eta: 0:00:36    time: 0.106455  data: 0.000202  max mem: 528\n","  [140/469]  eta: 0:00:34    time: 0.106458  data: 0.000210  max mem: 528\n","  [150/469]  eta: 0:00:33    time: 0.106474  data: 0.000203  max mem: 528\n","  [160/469]  eta: 0:00:32    time: 0.106456  data: 0.000177  max mem: 528\n","  [170/469]  eta: 0:00:31    time: 0.106463  data: 0.000182  max mem: 528\n","  [180/469]  eta: 0:00:30    time: 0.106461  data: 0.000204  max mem: 528\n","  [190/469]  eta: 0:00:29    time: 0.106455  data: 0.000214  max mem: 528\n","  [200/469]  eta: 0:00:28    time: 0.106446  data: 0.000211  max mem: 528\n","  [210/469]  eta: 0:00:27    time: 0.106420  data: 0.000202  max mem: 528\n","  [220/469]  eta: 0:00:26    time: 0.106425  data: 0.000258  max mem: 528\n","  [230/469]  eta: 0:00:25    time: 0.106416  data: 0.000259  max mem: 528\n","  [240/469]  eta: 0:00:24    time: 0.106428  data: 0.000215  max mem: 528\n","  [250/469]  eta: 0:00:23    time: 0.106477  data: 0.000207  max mem: 528\n","  [260/469]  eta: 0:00:22    time: 0.106478  data: 0.000208  max mem: 528\n","  [270/469]  eta: 0:00:21    time: 0.106474  data: 0.000219  max mem: 528\n","  [280/469]  eta: 0:00:20    time: 0.106449  data: 0.000287  max mem: 528\n","  [290/469]  eta: 0:00:19    time: 0.106467  data: 0.000291  max mem: 528\n","  [300/469]  eta: 0:00:17    time: 0.106476  data: 0.000225  max mem: 528\n","  [310/469]  eta: 0:00:16    time: 0.106450  data: 0.000231  max mem: 528\n","  [320/469]  eta: 0:00:15    time: 0.106454  data: 0.000233  max mem: 528\n","  [330/469]  eta: 0:00:14    time: 0.106448  data: 0.000234  max mem: 528\n","  [340/469]  eta: 0:00:13    time: 0.106426  data: 0.000230  max mem: 528\n","  [350/469]  eta: 0:00:12    time: 0.106422  data: 0.000239  max mem: 528\n","  [360/469]  eta: 0:00:11    time: 0.106454  data: 0.000236  max mem: 528\n","  [370/469]  eta: 0:00:10    time: 0.106431  data: 0.000234  max mem: 528\n","  [380/469]  eta: 0:00:09    time: 0.106396  data: 0.000389  max mem: 528\n","  [390/469]  eta: 0:00:08    time: 0.106437  data: 0.000380  max mem: 528\n","  [400/469]  eta: 0:00:07    time: 0.106473  data: 0.000232  max mem: 528\n","  [410/469]  eta: 0:00:06    time: 0.106500  data: 0.000239  max mem: 528\n","  [420/469]  eta: 0:00:05    time: 0.106466  data: 0.000218  max mem: 528\n","  [430/469]  eta: 0:00:04    time: 0.106356  data: 0.000177  max mem: 528\n","  [440/469]  eta: 0:00:03    time: 0.106390  data: 0.000192  max mem: 528\n","  [450/469]  eta: 0:00:02    time: 0.106460  data: 0.000245  max mem: 528\n","  [460/469]  eta: 0:00:00    time: 0.106495  data: 0.000230  max mem: 528\n","  [468/469]  eta: 0:00:00    time: 0.106480  data: 0.000222  max mem: 546\n"," Total time: 0:00:50 (0.106801 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:31    time: 0.398562  data: 0.287442  max mem: 546\n","  [10/79]  eta: 0:00:06    time: 0.101196  data: 0.026274  max mem: 546\n","  [20/79]  eta: 0:00:06    time: 0.088975  data: 0.000185  max mem: 546\n","  [30/79]  eta: 0:00:05    time: 0.106481  data: 0.000222  max mem: 546\n","  [40/79]  eta: 0:00:04    time: 0.106435  data: 0.000238  max mem: 546\n","  [50/79]  eta: 0:00:03    time: 0.106450  data: 0.000241  max mem: 546\n","  [60/79]  eta: 0:00:02    time: 0.106484  data: 0.000245  max mem: 546\n","  [70/79]  eta: 0:00:00    time: 0.106438  data: 0.000223  max mem: 546\n","  [78/79]  eta: 0:00:00    time: 0.106457  data: 0.000184  max mem: 546\n"," Total time: 0:00:08 (0.107876 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.0, Top5: 50.01\n","20-NN classifier result: Top1: 10.0, Top5: 50.0\n","100-NN classifier result: Top1: 10.0, Top5: 49.99\n","200-NN classifier result: Top1: 9.97, Top5: 49.97\n"],"name":"stdout"}]}]}
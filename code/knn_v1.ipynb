{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"knn_v1.ipynb","provenance":[],"mount_file_id":"1nG1HkybMNli1gEE-c8zYI9KCaNIbm8AC","authorship_tag":"ABX9TyNGa+0XE8iL2XBsxSe8ivaA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"0N7oMTbOgziO","executionInfo":{"status":"ok","timestamp":1623290598320,"user_tz":240,"elapsed":547,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"af5c1a99-0bcc-4b07-d968-b164bd3edaa0"},"source":["import os\n","os.getcwd()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"ipdfkICcg3ek","executionInfo":{"status":"ok","timestamp":1623290598321,"user_tz":240,"elapsed":7,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["os.chdir('/content/drive/MyDrive/DINO')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_te9wXlhSiZ","executionInfo":{"status":"ok","timestamp":1623290598959,"user_tz":240,"elapsed":645,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["import torch\n","from torch import nn\n","import torch.distributed as dist\n","import torch.backends.cudnn as cudnn\n","from torchvision import datasets\n","from torchvision import transforms as pth_transforms\n","\n","import numpy as np\n","\n","import utils\n","import vision_transformer as vits"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mP3Awpxxlw3I","executionInfo":{"status":"ok","timestamp":1623290598963,"user_tz":240,"elapsed":12,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, images, labels=None, transforms=None):\n","        self.X = images\n","        self.y = labels\n","        self.transforms = transforms\n","         \n","    def __len__(self):\n","        return (len(self.X))\n","    \n","    def __getitem__(self, i):\n","        data = self.X[i]\n","        #print(data.shape)\n","        data = np.asarray(data).astype(np.float32)\n","        #data = np.asarray(data).astype(np.uint8).reshape(28, 28, 1)\n","        \n","        if self.transforms:\n","            data = self.transforms(data)\n","            \n","        if self.y is not None:\n","            return (data, self.y[i])\n","        else:\n","            return data"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"cDJv-XbKhVi5","executionInfo":{"status":"ok","timestamp":1623290598963,"user_tz":240,"elapsed":10,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["def extract_feature_pipeline(args):\n","    # ============ preparing data ... ============\n","    train_dataset = datasets.FashionMNIST(args.data_path, download=True, train=False)\n","    val_dataset = datasets.FashionMNIST(args.data_path, download=True, train=True)\n","    X_train = torch.flatten(train_dataset.data, start_dim=1).numpy()/255\n","    y_train = train_dataset.targets.numpy()\n","\n","    X_val = torch.flatten(val_dataset.data, start_dim=1).numpy()/255\n","    y_val = val_dataset.targets.numpy()\n","    dataset_train = CustomDataset(X_train, y_train)\n","    dataset_val = CustomDataset(X_val, y_val)\n","    sampler = torch.utils.data.DistributedSampler(dataset_train, shuffle=False)\n","    data_loader_train = torch.utils.data.DataLoader(\n","        dataset_train,\n","        sampler=sampler,\n","        batch_size=args.batch_size_per_gpu,\n","        num_workers=args.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","    data_loader_val = torch.utils.data.DataLoader(\n","        dataset_val,\n","        batch_size=args.batch_size_per_gpu,\n","        num_workers=args.num_workers,\n","        pin_memory=True,\n","        drop_last=False,\n","    )\n","    print(f\"Data loaded with {len(dataset_train)} train and {len(dataset_val)} val imgs.\")\n","\n","    # ============ building network ... ============\n","    model = vits.__dict__[args.arch](patch_size=args.patch_size, num_classes=0)\n","    print(f\"Model {args.arch} {args.patch_size}x{args.patch_size} built.\")\n","    model.cuda()\n","    utils.load_pretrained_weights(model, args.pretrained_weights, args.checkpoint_key, args.arch, args.patch_size)\n","    model.eval()\n","\n","    # ============ extract features ... ============\n","    print(\"Extracting features for train set...\")\n","    train_features = extract_features(model, data_loader_train)\n","    print(\"Extracting features for val set...\")\n","    test_features = extract_features(model, data_loader_val)\n","\n","    if utils.get_rank() == 0:\n","        train_features = nn.functional.normalize(train_features, dim=1, p=2)\n","        test_features = nn.functional.normalize(test_features, dim=1, p=2)\n","\n","    train_labels = torch.tensor([s for s in dataset_train.y]).long()\n","    test_labels = torch.tensor([s for s in dataset_val.y]).long()\n","    # save features and labels\n","    if args.dump_features and dist.get_rank() == 0:\n","        torch.save(train_features.cpu(), os.path.join(args.dump_features, \"trainfeat.pth\"))\n","        torch.save(test_features.cpu(), os.path.join(args.dump_features, \"testfeat.pth\"))\n","        torch.save(train_labels.cpu(), os.path.join(args.dump_features, \"trainlabels.pth\"))\n","        torch.save(test_labels.cpu(), os.path.join(args.dump_features, \"testlabels.pth\"))\n","    return train_features, test_features, train_labels, test_labels\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"FoIvstOuiWeM","executionInfo":{"status":"ok","timestamp":1623290598964,"user_tz":240,"elapsed":10,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["@torch.no_grad()\n","def extract_features(model, data_loader):\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    features = None\n","    for samples, index in metric_logger.log_every(data_loader, 10):\n","        samples = samples.cuda(non_blocking=True)\n","        index = index.cuda(non_blocking=True)\n","        feats = model(samples).clone()\n","\n","        # init storage feature matrix\n","        if dist.get_rank() == 0 and features is None:\n","            features = torch.zeros(len(data_loader.dataset), feats.shape[-1])\n","            if args.use_cuda:\n","                features = features.cuda(non_blocking=True)\n","            print(f\"Storing features into tensor of shape {features.shape}\")\n","\n","        # get indexes from all processes\n","        y_all = torch.empty(dist.get_world_size(), index.size(0), dtype=index.dtype, device=index.device)\n","        y_l = list(y_all.unbind(0))\n","        y_all_reduce = torch.distributed.all_gather(y_l, index, async_op=True)\n","        y_all_reduce.wait()\n","        index_all = torch.cat(y_l)\n","\n","        # share features between processes\n","        feats_all = torch.empty(\n","            dist.get_world_size(),\n","            feats.size(0),\n","            feats.size(1),\n","            dtype=feats.dtype,\n","            device=feats.device,\n","        )\n","        output_l = list(feats_all.unbind(0))\n","        output_all_reduce = torch.distributed.all_gather(output_l, feats, async_op=True)\n","        output_all_reduce.wait()\n","\n","        # update storage feature matrix\n","        if dist.get_rank() == 0:\n","            if args.use_cuda:\n","                features.index_copy_(0, index_all, torch.cat(output_l))\n","            else:\n","                features.index_copy_(0, index_all.cpu(), torch.cat(output_l).cpu())\n","    return features"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Re8wtY4ZikZK","executionInfo":{"status":"ok","timestamp":1623290598964,"user_tz":240,"elapsed":9,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["@torch.no_grad()\n","def knn_classifier(train_features, train_labels, test_features, test_labels, k, T, num_classes=1000):\n","    top1, top5, total = 0.0, 0.0, 0\n","    train_features = train_features.t()\n","    num_test_images, num_chunks = test_labels.shape[0], 100\n","    imgs_per_chunk = num_test_images // num_chunks\n","    retrieval_one_hot = torch.zeros(k, num_classes).cuda()\n","    for idx in range(0, num_test_images, imgs_per_chunk):\n","        # get the features for test images\n","        features = test_features[\n","            idx : min((idx + imgs_per_chunk), num_test_images), :\n","        ]\n","        targets = test_labels[idx : min((idx + imgs_per_chunk), num_test_images)]\n","        batch_size = targets.shape[0]\n","\n","        # calculate the dot product and compute top-k neighbors\n","        similarity = torch.mm(features, train_features)\n","        distances, indices = similarity.topk(k, largest=True, sorted=True)\n","        candidates = train_labels.view(1, -1).expand(batch_size, -1)\n","        retrieved_neighbors = torch.gather(candidates, 1, indices)\n","\n","        retrieval_one_hot.resize_(batch_size * k, num_classes).zero_()\n","        retrieval_one_hot.scatter_(1, retrieved_neighbors.view(-1, 1), 1)\n","        distances_transform = distances.clone().div_(T).exp_()\n","        probs = torch.sum(\n","            torch.mul(\n","                retrieval_one_hot.view(batch_size, -1, num_classes),\n","                distances_transform.view(batch_size, -1, 1),\n","            ),\n","            1,\n","        )\n","        _, predictions = probs.sort(1, True)\n","\n","        # find the predictions that match the target\n","        correct = predictions.eq(targets.data.view(-1, 1))\n","        top1 = top1 + correct.narrow(1, 0, 1).sum().item()\n","        top5 = top5 + correct.narrow(1, 0, 5).sum().item()\n","        total += targets.size(0)\n","    top1 = top1 * 100.0 / total\n","    top5 = top5 * 100.0 / total\n","    return top1, top5"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZvJNZLNBi_4c","executionInfo":{"status":"ok","timestamp":1623290598965,"user_tz":240,"elapsed":9,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["class ReturnIndexDataset(datasets.ImageFolder):\n","    def __getitem__(self, idx):\n","        img, lab = super(ReturnIndexDataset, self).__getitem__(idx)\n","        return img, idx"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"qgrwZAOAjsf9","executionInfo":{"status":"ok","timestamp":1623290598965,"user_tz":240,"elapsed":9,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}}},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './checkpoint.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","\n","args=AttrDict(args)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yw5hoaKmjFfl","executionInfo":{"status":"ok","timestamp":1623290602627,"user_tz":240,"elapsed":3670,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"b2546fa2-ec90-43a6-953c-2da3264ab3cc"},"source":["utils.init_distributed_mode(args)\n","print(\"git:\\n  {}\\n\".format(utils.get_sha()))\n","print(\"\\n\".join(\"%s: %s\" % (k, str(v)) for k, v in sorted(dict(vars(args)).items())))\n","cudnn.benchmark = True"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Will run the code on one GPU.\n","| distributed init (rank 0): env://\n","git:\n","  sha: N/A, status: clean, branch: N/A\n","\n","arch: vit_tiny\n","batch_size_per_gpu: 128\n","checkpoint_key: teacher\n","data_path: ./data/FashionMNIST\n","dist_url: env://\n","dump_features: None\n","gpu: 0\n","load_features: None\n","local_rank: 0\n","nb_knn: [10, 20, 100, 200]\n","num_workers: 10\n","patch_size: 4\n","pretrained_weights: ./checkpoint.pth\n","rank: 0\n","temperature: 0.07\n","use_cuda: True\n","world_size: 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVgoZbvcjJJX","executionInfo":{"status":"ok","timestamp":1623290632704,"user_tz":240,"elapsed":30081,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"84014df0-c633-429e-a320-8ad5f9b2c8ec"},"source":["#if args.load_features:\n","#    train_features = torch.load(os.path.join(args.load_features, \"trainfeat.pth\"))\n","#    test_features = torch.load(os.path.join(args.load_features, \"testfeat.pth\"))\n","#    train_labels = torch.load(os.path.join(args.load_features, \"trainlabels.pth\"))\n","#    test_labels = torch.load(os.path.join(args.load_features, \"testlabels.pth\"))\n","#else:\n","#    # need to extract features !\n","#    train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Data loaded with 10000 train and 60000 val imgs.\n","Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./checkpoint.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:37    time: 0.469524  data: 0.378897  max mem: 301\n","  [10/79]  eta: 0:00:05    time: 0.075526  data: 0.034621  max mem: 308\n","  [20/79]  eta: 0:00:03    time: 0.043028  data: 0.000220  max mem: 403\n","  [30/79]  eta: 0:00:02    time: 0.049933  data: 0.000251  max mem: 439\n","  [40/79]  eta: 0:00:02    time: 0.049903  data: 0.000244  max mem: 439\n","  [50/79]  eta: 0:00:01    time: 0.049874  data: 0.000384  max mem: 439\n","  [60/79]  eta: 0:00:01    time: 0.049887  data: 0.000604  max mem: 439\n","  [70/79]  eta: 0:00:00    time: 0.049890  data: 0.000424  max mem: 439\n","  [78/79]  eta: 0:00:00    time: 0.056657  data: 0.000181  max mem: 439\n"," Total time: 0:00:04 (0.057938 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:38    time: 0.465593  data: 0.367805  max mem: 439\n","  [ 10/469]  eta: 0:00:33    time: 0.072841  data: 0.033628  max mem: 445\n","  [ 20/469]  eta: 0:00:27    time: 0.041736  data: 0.000210  max mem: 445\n","  [ 30/469]  eta: 0:00:25    time: 0.049928  data: 0.000238  max mem: 445\n","  [ 40/469]  eta: 0:00:24    time: 0.049822  data: 0.000489  max mem: 445\n","  [ 50/469]  eta: 0:00:22    time: 0.049797  data: 0.000488  max mem: 445\n","  [ 60/469]  eta: 0:00:22    time: 0.049921  data: 0.000268  max mem: 445\n","  [ 70/469]  eta: 0:00:21    time: 0.049949  data: 0.000258  max mem: 445\n","  [ 80/469]  eta: 0:00:20    time: 0.049942  data: 0.000255  max mem: 445\n","  [ 90/469]  eta: 0:00:19    time: 0.049896  data: 0.000237  max mem: 445\n","  [100/469]  eta: 0:00:19    time: 0.049902  data: 0.000232  max mem: 445\n","  [110/469]  eta: 0:00:18    time: 0.049952  data: 0.000262  max mem: 445\n","  [120/469]  eta: 0:00:18    time: 0.049966  data: 0.000344  max mem: 445\n","  [130/469]  eta: 0:00:17    time: 0.049962  data: 0.000419  max mem: 445\n","  [140/469]  eta: 0:00:17    time: 0.049945  data: 0.000334  max mem: 445\n","  [150/469]  eta: 0:00:16    time: 0.049936  data: 0.000265  max mem: 445\n","  [160/469]  eta: 0:00:15    time: 0.049958  data: 0.000291  max mem: 445\n","  [170/469]  eta: 0:00:15    time: 0.049967  data: 0.000289  max mem: 445\n","  [180/469]  eta: 0:00:14    time: 0.049964  data: 0.000273  max mem: 445\n","  [190/469]  eta: 0:00:14    time: 0.049959  data: 0.000267  max mem: 445\n","  [200/469]  eta: 0:00:13    time: 0.049952  data: 0.000268  max mem: 445\n","  [210/469]  eta: 0:00:13    time: 0.049922  data: 0.000257  max mem: 445\n","  [220/469]  eta: 0:00:12    time: 0.049799  data: 0.000211  max mem: 445\n","  [230/469]  eta: 0:00:12    time: 0.049802  data: 0.000219  max mem: 445\n","  [240/469]  eta: 0:00:11    time: 0.049886  data: 0.000335  max mem: 445\n","  [250/469]  eta: 0:00:11    time: 0.049883  data: 0.000335  max mem: 445\n","  [260/469]  eta: 0:00:10    time: 0.049872  data: 0.000216  max mem: 445\n","  [270/469]  eta: 0:00:10    time: 0.049874  data: 0.000203  max mem: 445\n","  [280/469]  eta: 0:00:09    time: 0.049875  data: 0.000238  max mem: 445\n","  [290/469]  eta: 0:00:09    time: 0.049866  data: 0.000260  max mem: 445\n","  [300/469]  eta: 0:00:08    time: 0.049861  data: 0.000323  max mem: 445\n","  [310/469]  eta: 0:00:08    time: 0.049856  data: 0.000321  max mem: 445\n","  [320/469]  eta: 0:00:07    time: 0.049862  data: 0.000260  max mem: 445\n","  [330/469]  eta: 0:00:07    time: 0.049864  data: 0.000371  max mem: 445\n","  [340/469]  eta: 0:00:06    time: 0.049869  data: 0.000382  max mem: 445\n","  [350/469]  eta: 0:00:06    time: 0.049872  data: 0.000355  max mem: 483\n","  [360/469]  eta: 0:00:05    time: 0.049865  data: 0.000343  max mem: 483\n","  [370/469]  eta: 0:00:05    time: 0.049832  data: 0.000335  max mem: 483\n","  [380/469]  eta: 0:00:04    time: 0.049848  data: 0.000331  max mem: 483\n","  [390/469]  eta: 0:00:03    time: 0.049888  data: 0.000204  max mem: 483\n","  [400/469]  eta: 0:00:03    time: 0.049887  data: 0.000212  max mem: 483\n","  [410/469]  eta: 0:00:02    time: 0.049878  data: 0.000256  max mem: 483\n","  [420/469]  eta: 0:00:02    time: 0.049871  data: 0.000253  max mem: 483\n","  [430/469]  eta: 0:00:01    time: 0.049877  data: 0.000251  max mem: 483\n","  [440/469]  eta: 0:00:01    time: 0.049886  data: 0.000253  max mem: 483\n","  [450/469]  eta: 0:00:00    time: 0.049878  data: 0.000243  max mem: 483\n","  [460/469]  eta: 0:00:00    time: 0.049870  data: 0.000208  max mem: 483\n","  [468/469]  eta: 0:00:00    time: 0.056682  data: 0.000149  max mem: 483\n"," Total time: 0:00:24 (0.051245 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.0, Top5: 49.998333333333335\n","20-NN classifier result: Top1: 10.0, Top5: 50.0\n","100-NN classifier result: Top1: 9.996666666666666, Top5: 50.0\n","200-NN classifier result: Top1: 9.996666666666666, Top5: 49.995\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WtAalfmyqA5-","executionInfo":{"status":"ok","timestamp":1623290663258,"user_tz":240,"elapsed":30576,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"dce7a3cf-8933-4ed3-a6d7-5a1d8d139c3b"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './checkpoint0000.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Data loaded with 10000 train and 60000 val imgs.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./checkpoint0000.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:35    time: 0.445867  data: 0.384794  max mem: 1007\n","  [10/79]  eta: 0:00:04    time: 0.071056  data: 0.035155  max mem: 1007\n","  [20/79]  eta: 0:00:03    time: 0.041723  data: 0.000200  max mem: 1007\n","  [30/79]  eta: 0:00:02    time: 0.049900  data: 0.000242  max mem: 1007\n","  [40/79]  eta: 0:00:02    time: 0.049928  data: 0.000275  max mem: 1007\n","  [50/79]  eta: 0:00:01    time: 0.049915  data: 0.000274  max mem: 1007\n","  [60/79]  eta: 0:00:01    time: 0.049913  data: 0.000269  max mem: 1007\n","  [70/79]  eta: 0:00:00    time: 0.049890  data: 0.000191  max mem: 1007\n","  [78/79]  eta: 0:00:00    time: 0.049995  data: 0.000144  max mem: 1007\n"," Total time: 0:00:04 (0.055736 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:38    time: 0.466127  data: 0.390942  max mem: 1007\n","  [ 10/469]  eta: 0:00:33    time: 0.072917  data: 0.035746  max mem: 1007\n","  [ 20/469]  eta: 0:00:27    time: 0.041754  data: 0.000231  max mem: 1007\n","  [ 30/469]  eta: 0:00:25    time: 0.049881  data: 0.000233  max mem: 1007\n","  [ 40/469]  eta: 0:00:24    time: 0.049828  data: 0.000329  max mem: 1007\n","  [ 50/469]  eta: 0:00:22    time: 0.049842  data: 0.000353  max mem: 1007\n","  [ 60/469]  eta: 0:00:22    time: 0.049883  data: 0.000544  max mem: 1007\n","  [ 70/469]  eta: 0:00:21    time: 0.049885  data: 0.000535  max mem: 1007\n","  [ 80/469]  eta: 0:00:20    time: 0.049890  data: 0.000256  max mem: 1007\n","  [ 90/469]  eta: 0:00:19    time: 0.049899  data: 0.000252  max mem: 1007\n","  [100/469]  eta: 0:00:19    time: 0.049890  data: 0.000264  max mem: 1007\n","  [110/469]  eta: 0:00:18    time: 0.049898  data: 0.000261  max mem: 1007\n","  [120/469]  eta: 0:00:18    time: 0.049897  data: 0.000335  max mem: 1007\n","  [130/469]  eta: 0:00:17    time: 0.049871  data: 0.000331  max mem: 1007\n","  [140/469]  eta: 0:00:17    time: 0.049876  data: 0.000220  max mem: 1007\n","  [150/469]  eta: 0:00:16    time: 0.049864  data: 0.000196  max mem: 1007\n","  [160/469]  eta: 0:00:15    time: 0.049819  data: 0.000214  max mem: 1007\n","  [170/469]  eta: 0:00:15    time: 0.049828  data: 0.000349  max mem: 1007\n","  [180/469]  eta: 0:00:14    time: 0.049868  data: 0.000372  max mem: 1007\n","  [190/469]  eta: 0:00:14    time: 0.049880  data: 0.000352  max mem: 1007\n","  [200/469]  eta: 0:00:13    time: 0.049882  data: 0.000347  max mem: 1007\n","  [210/469]  eta: 0:00:13    time: 0.049877  data: 0.000346  max mem: 1007\n","  [220/469]  eta: 0:00:12    time: 0.049883  data: 0.000418  max mem: 1007\n","  [230/469]  eta: 0:00:12    time: 0.049887  data: 0.000336  max mem: 1007\n","  [240/469]  eta: 0:00:11    time: 0.049883  data: 0.000305  max mem: 1007\n","  [250/469]  eta: 0:00:11    time: 0.049874  data: 0.000304  max mem: 1007\n","  [260/469]  eta: 0:00:10    time: 0.049871  data: 0.000612  max mem: 1007\n","  [270/469]  eta: 0:00:10    time: 0.049850  data: 0.000585  max mem: 1007\n","  [280/469]  eta: 0:00:09    time: 0.049820  data: 0.000186  max mem: 1007\n","  [290/469]  eta: 0:00:09    time: 0.049847  data: 0.000249  max mem: 1007\n","  [300/469]  eta: 0:00:08    time: 0.049855  data: 0.000340  max mem: 1007\n","  [310/469]  eta: 0:00:08    time: 0.049883  data: 0.000300  max mem: 1007\n","  [320/469]  eta: 0:00:07    time: 0.049901  data: 0.000425  max mem: 1007\n","  [330/469]  eta: 0:00:07    time: 0.049883  data: 0.000474  max mem: 1007\n","  [340/469]  eta: 0:00:06    time: 0.049884  data: 0.000294  max mem: 1007\n","  [350/469]  eta: 0:00:06    time: 0.049887  data: 0.000344  max mem: 1007\n","  [360/469]  eta: 0:00:05    time: 0.049899  data: 0.000342  max mem: 1007\n","  [370/469]  eta: 0:00:05    time: 0.049901  data: 0.000427  max mem: 1007\n","  [380/469]  eta: 0:00:04    time: 0.049847  data: 0.000389  max mem: 1007\n","  [390/469]  eta: 0:00:03    time: 0.049838  data: 0.000211  max mem: 1007\n","  [400/469]  eta: 0:00:03    time: 0.049870  data: 0.000330  max mem: 1007\n","  [410/469]  eta: 0:00:02    time: 0.049906  data: 0.000365  max mem: 1007\n","  [420/469]  eta: 0:00:02    time: 0.049930  data: 0.000283  max mem: 1007\n","  [430/469]  eta: 0:00:01    time: 0.049922  data: 0.000246  max mem: 1007\n","  [440/469]  eta: 0:00:01    time: 0.049915  data: 0.000219  max mem: 1007\n","  [450/469]  eta: 0:00:00    time: 0.049907  data: 0.000178  max mem: 1007\n","  [460/469]  eta: 0:00:00    time: 0.049921  data: 0.000140  max mem: 1007\n","  [468/469]  eta: 0:00:00    time: 0.049915  data: 0.000142  max mem: 1007\n"," Total time: 0:00:23 (0.050965 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.0, Top5: 50.001666666666665\n","20-NN classifier result: Top1: 10.0, Top5: 50.00333333333333\n","100-NN classifier result: Top1: 9.996666666666666, Top5: 50.00333333333333\n","200-NN classifier result: Top1: 9.996666666666666, Top5: 49.998333333333335\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIGHju6HqF9j","executionInfo":{"status":"ok","timestamp":1623290694732,"user_tz":240,"elapsed":31483,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"4a0a945a-0c18-4b47-abed-f9f747ba80c1"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './checkpoint0020.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Data loaded with 10000 train and 60000 val imgs.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./checkpoint0020.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:34    time: 0.440798  data: 0.377149  max mem: 1007\n","  [10/79]  eta: 0:00:04    time: 0.070591  data: 0.034461  max mem: 1007\n","  [20/79]  eta: 0:00:03    time: 0.041736  data: 0.000280  max mem: 1007\n","  [30/79]  eta: 0:00:02    time: 0.049936  data: 0.000371  max mem: 1007\n","  [40/79]  eta: 0:00:02    time: 0.049964  data: 0.000359  max mem: 1007\n","  [50/79]  eta: 0:00:01    time: 0.049933  data: 0.000294  max mem: 1007\n","  [60/79]  eta: 0:00:01    time: 0.049926  data: 0.000247  max mem: 1007\n","  [70/79]  eta: 0:00:00    time: 0.049924  data: 0.000236  max mem: 1007\n","  [78/79]  eta: 0:00:00    time: 0.050027  data: 0.000198  max mem: 1007\n"," Total time: 0:00:04 (0.055606 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:29    time: 0.447369  data: 0.356323  max mem: 1007\n","  [ 10/469]  eta: 0:00:32    time: 0.071247  data: 0.032649  max mem: 1007\n","  [ 20/469]  eta: 0:00:27    time: 0.041767  data: 0.000395  max mem: 1007\n","  [ 30/469]  eta: 0:00:25    time: 0.049933  data: 0.000379  max mem: 1007\n","  [ 40/469]  eta: 0:00:23    time: 0.049980  data: 0.000252  max mem: 1007\n","  [ 50/469]  eta: 0:00:22    time: 0.049941  data: 0.000220  max mem: 1007\n","  [ 60/469]  eta: 0:00:21    time: 0.049918  data: 0.000245  max mem: 1007\n","  [ 70/469]  eta: 0:00:21    time: 0.049953  data: 0.000286  max mem: 1007\n","  [ 80/469]  eta: 0:00:20    time: 0.049952  data: 0.000268  max mem: 1007\n","  [ 90/469]  eta: 0:00:19    time: 0.049926  data: 0.000274  max mem: 1007\n","  [100/469]  eta: 0:00:19    time: 0.049913  data: 0.000274  max mem: 1007\n","  [110/469]  eta: 0:00:18    time: 0.049928  data: 0.000264  max mem: 1007\n","  [120/469]  eta: 0:00:18    time: 0.049940  data: 0.000260  max mem: 1007\n","  [130/469]  eta: 0:00:17    time: 0.049923  data: 0.000286  max mem: 1007\n","  [140/469]  eta: 0:00:16    time: 0.049913  data: 0.000457  max mem: 1007\n","  [150/469]  eta: 0:00:16    time: 0.049919  data: 0.000446  max mem: 1007\n","  [160/469]  eta: 0:00:15    time: 0.049926  data: 0.000276  max mem: 1007\n","  [170/469]  eta: 0:00:15    time: 0.049935  data: 0.000415  max mem: 1007\n","  [180/469]  eta: 0:00:14    time: 0.049931  data: 0.000420  max mem: 1007\n","  [190/469]  eta: 0:00:14    time: 0.049927  data: 0.000258  max mem: 1007\n","  [200/469]  eta: 0:00:13    time: 0.049915  data: 0.000277  max mem: 1007\n","  [210/469]  eta: 0:00:13    time: 0.049908  data: 0.000387  max mem: 1007\n","  [220/469]  eta: 0:00:12    time: 0.049919  data: 0.000360  max mem: 1007\n","  [230/469]  eta: 0:00:12    time: 0.049923  data: 0.000268  max mem: 1007\n","  [240/469]  eta: 0:00:11    time: 0.049904  data: 0.000278  max mem: 1007\n","  [250/469]  eta: 0:00:11    time: 0.049895  data: 0.000282  max mem: 1007\n","  [260/469]  eta: 0:00:10    time: 0.049900  data: 0.000292  max mem: 1007\n","  [270/469]  eta: 0:00:10    time: 0.049885  data: 0.000297  max mem: 1007\n","  [280/469]  eta: 0:00:09    time: 0.049893  data: 0.000286  max mem: 1007\n","  [290/469]  eta: 0:00:09    time: 0.049896  data: 0.000268  max mem: 1007\n","  [300/469]  eta: 0:00:08    time: 0.049882  data: 0.000269  max mem: 1007\n","  [310/469]  eta: 0:00:08    time: 0.049879  data: 0.000286  max mem: 1007\n","  [320/469]  eta: 0:00:07    time: 0.049850  data: 0.000272  max mem: 1007\n","  [330/469]  eta: 0:00:07    time: 0.049861  data: 0.000281  max mem: 1007\n","  [340/469]  eta: 0:00:06    time: 0.049845  data: 0.000254  max mem: 1007\n","  [350/469]  eta: 0:00:06    time: 0.049835  data: 0.000238  max mem: 1007\n","  [360/469]  eta: 0:00:05    time: 0.049878  data: 0.000283  max mem: 1007\n","  [370/469]  eta: 0:00:05    time: 0.049872  data: 0.000280  max mem: 1007\n","  [380/469]  eta: 0:00:04    time: 0.049880  data: 0.000245  max mem: 1007\n","  [390/469]  eta: 0:00:03    time: 0.049859  data: 0.000300  max mem: 1007\n","  [400/469]  eta: 0:00:03    time: 0.049852  data: 0.000394  max mem: 1007\n","  [410/469]  eta: 0:00:02    time: 0.049858  data: 0.000289  max mem: 1007\n","  [420/469]  eta: 0:00:02    time: 0.049901  data: 0.000205  max mem: 1007\n","  [430/469]  eta: 0:00:01    time: 0.049942  data: 0.000275  max mem: 1007\n","  [440/469]  eta: 0:00:01    time: 0.049900  data: 0.000281  max mem: 1007\n","  [450/469]  eta: 0:00:00    time: 0.049906  data: 0.000253  max mem: 1007\n","  [460/469]  eta: 0:00:00    time: 0.049877  data: 0.000227  max mem: 1007\n","  [468/469]  eta: 0:00:00    time: 0.049859  data: 0.000199  max mem: 1007\n"," Total time: 0:00:23 (0.050991 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.0, Top5: 50.0\n","20-NN classifier result: Top1: 10.0, Top5: 50.001666666666665\n","100-NN classifier result: Top1: 9.996666666666666, Top5: 50.001666666666665\n","200-NN classifier result: Top1: 9.996666666666666, Top5: 49.99666666666667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyPaQuYSqG_6","executionInfo":{"status":"ok","timestamp":1623290725950,"user_tz":240,"elapsed":31223,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"b40d0b9d-cf81-46db-8df4-6600197dee94"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './checkpoint0040.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Data loaded with 10000 train and 60000 val imgs.\n","Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./checkpoint0040.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:36    time: 0.461666  data: 0.402214  max mem: 1007\n","  [10/79]  eta: 0:00:05    time: 0.072504  data: 0.037064  max mem: 1007\n","  [20/79]  eta: 0:00:03    time: 0.041732  data: 0.000357  max mem: 1007\n","  [30/79]  eta: 0:00:02    time: 0.049911  data: 0.000357  max mem: 1007\n","  [40/79]  eta: 0:00:02    time: 0.049942  data: 0.000401  max mem: 1007\n","  [50/79]  eta: 0:00:01    time: 0.049845  data: 0.000231  max mem: 1007\n","  [60/79]  eta: 0:00:01    time: 0.049841  data: 0.000531  max mem: 1007\n","  [70/79]  eta: 0:00:00    time: 0.049930  data: 0.000521  max mem: 1007\n","  [78/79]  eta: 0:00:00    time: 0.050041  data: 0.000160  max mem: 1007\n"," Total time: 0:00:04 (0.055961 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:46    time: 0.482054  data: 0.378443  max mem: 1007\n","  [ 10/469]  eta: 0:00:34    time: 0.074364  data: 0.034873  max mem: 1007\n","  [ 20/469]  eta: 0:00:28    time: 0.041758  data: 0.000372  max mem: 1007\n","  [ 30/469]  eta: 0:00:25    time: 0.049942  data: 0.000252  max mem: 1007\n","  [ 40/469]  eta: 0:00:24    time: 0.049911  data: 0.000268  max mem: 1007\n","  [ 50/469]  eta: 0:00:23    time: 0.049891  data: 0.000265  max mem: 1007\n","  [ 60/469]  eta: 0:00:22    time: 0.049929  data: 0.000270  max mem: 1007\n","  [ 70/469]  eta: 0:00:21    time: 0.049932  data: 0.000272  max mem: 1007\n","  [ 80/469]  eta: 0:00:20    time: 0.049925  data: 0.000270  max mem: 1007\n","  [ 90/469]  eta: 0:00:20    time: 0.049921  data: 0.000268  max mem: 1007\n","  [100/469]  eta: 0:00:19    time: 0.049919  data: 0.000262  max mem: 1007\n","  [110/469]  eta: 0:00:18    time: 0.049927  data: 0.000316  max mem: 1007\n","  [120/469]  eta: 0:00:18    time: 0.049918  data: 0.000378  max mem: 1007\n","  [130/469]  eta: 0:00:17    time: 0.049907  data: 0.000332  max mem: 1007\n","  [140/469]  eta: 0:00:17    time: 0.049923  data: 0.000345  max mem: 1007\n","  [150/469]  eta: 0:00:16    time: 0.049931  data: 0.000298  max mem: 1007\n","  [160/469]  eta: 0:00:15    time: 0.049939  data: 0.000191  max mem: 1007\n","  [170/469]  eta: 0:00:15    time: 0.049893  data: 0.000197  max mem: 1007\n","  [180/469]  eta: 0:00:14    time: 0.049840  data: 0.000222  max mem: 1007\n","  [190/469]  eta: 0:00:14    time: 0.049841  data: 0.000230  max mem: 1007\n","  [200/469]  eta: 0:00:13    time: 0.049880  data: 0.000244  max mem: 1007\n","  [210/469]  eta: 0:00:13    time: 0.049921  data: 0.000266  max mem: 1007\n","  [220/469]  eta: 0:00:12    time: 0.049889  data: 0.000213  max mem: 1007\n","  [230/469]  eta: 0:00:12    time: 0.049886  data: 0.000208  max mem: 1007\n","  [240/469]  eta: 0:00:11    time: 0.049929  data: 0.000237  max mem: 1007\n","  [250/469]  eta: 0:00:11    time: 0.049931  data: 0.000240  max mem: 1007\n","  [260/469]  eta: 0:00:10    time: 0.049926  data: 0.000274  max mem: 1007\n","  [270/469]  eta: 0:00:10    time: 0.049916  data: 0.000272  max mem: 1007\n","  [280/469]  eta: 0:00:09    time: 0.049914  data: 0.000264  max mem: 1007\n","  [290/469]  eta: 0:00:09    time: 0.049925  data: 0.000286  max mem: 1007\n","  [300/469]  eta: 0:00:08    time: 0.049918  data: 0.000302  max mem: 1007\n","  [310/469]  eta: 0:00:08    time: 0.049907  data: 0.000295  max mem: 1007\n","  [320/469]  eta: 0:00:07    time: 0.049900  data: 0.000251  max mem: 1007\n","  [330/469]  eta: 0:00:07    time: 0.049893  data: 0.000248  max mem: 1007\n","  [340/469]  eta: 0:00:06    time: 0.049898  data: 0.000280  max mem: 1007\n","  [350/469]  eta: 0:00:06    time: 0.049907  data: 0.000294  max mem: 1007\n","  [360/469]  eta: 0:00:05    time: 0.049917  data: 0.000388  max mem: 1007\n","  [370/469]  eta: 0:00:05    time: 0.049933  data: 0.000762  max mem: 1007\n","  [380/469]  eta: 0:00:04    time: 0.049930  data: 0.000670  max mem: 1007\n","  [390/469]  eta: 0:00:03    time: 0.049918  data: 0.000552  max mem: 1007\n","  [400/469]  eta: 0:00:03    time: 0.049923  data: 0.000712  max mem: 1007\n","  [410/469]  eta: 0:00:02    time: 0.049916  data: 0.000478  max mem: 1007\n","  [420/469]  eta: 0:00:02    time: 0.049899  data: 0.000314  max mem: 1007\n","  [430/469]  eta: 0:00:01    time: 0.049904  data: 0.000293  max mem: 1007\n","  [440/469]  eta: 0:00:01    time: 0.049909  data: 0.000307  max mem: 1007\n","  [450/469]  eta: 0:00:00    time: 0.049900  data: 0.000277  max mem: 1007\n","  [460/469]  eta: 0:00:00    time: 0.049888  data: 0.000232  max mem: 1007\n","  [468/469]  eta: 0:00:00    time: 0.049882  data: 0.000205  max mem: 1007\n"," Total time: 0:00:23 (0.051051 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.0, Top5: 50.0\n","20-NN classifier result: Top1: 10.0, Top5: 50.001666666666665\n","100-NN classifier result: Top1: 9.996666666666666, Top5: 50.001666666666665\n","200-NN classifier result: Top1: 9.996666666666666, Top5: 49.99666666666667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HAzuz9QtqJHh","executionInfo":{"status":"ok","timestamp":1623290756542,"user_tz":240,"elapsed":30609,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"75a577c8-6af2-4a63-e508-73ccd32ea0e5"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './checkpoint0060.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Data loaded with 10000 train and 60000 val imgs.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./checkpoint0060.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:35    time: 0.453005  data: 0.387749  max mem: 1007\n","  [10/79]  eta: 0:00:04    time: 0.071704  data: 0.035455  max mem: 1007\n","  [20/79]  eta: 0:00:03    time: 0.041763  data: 0.000226  max mem: 1007\n","  [30/79]  eta: 0:00:02    time: 0.049926  data: 0.000198  max mem: 1007\n","  [40/79]  eta: 0:00:02    time: 0.049937  data: 0.000226  max mem: 1007\n","  [50/79]  eta: 0:00:01    time: 0.049975  data: 0.000260  max mem: 1007\n","  [60/79]  eta: 0:00:01    time: 0.049962  data: 0.000203  max mem: 1007\n","  [70/79]  eta: 0:00:00    time: 0.049932  data: 0.000138  max mem: 1007\n","  [78/79]  eta: 0:00:00    time: 0.050034  data: 0.000148  max mem: 1007\n"," Total time: 0:00:04 (0.055843 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:34    time: 0.457078  data: 0.363896  max mem: 1007\n","  [ 10/469]  eta: 0:00:33    time: 0.072053  data: 0.033264  max mem: 1007\n","  [ 20/469]  eta: 0:00:27    time: 0.041718  data: 0.000227  max mem: 1007\n","  [ 30/469]  eta: 0:00:25    time: 0.049846  data: 0.000209  max mem: 1007\n","  [ 40/469]  eta: 0:00:23    time: 0.049837  data: 0.000228  max mem: 1007\n","  [ 50/469]  eta: 0:00:22    time: 0.049863  data: 0.000268  max mem: 1007\n","  [ 60/469]  eta: 0:00:22    time: 0.049858  data: 0.000248  max mem: 1007\n","  [ 70/469]  eta: 0:00:21    time: 0.049862  data: 0.000248  max mem: 1007\n","  [ 80/469]  eta: 0:00:20    time: 0.049888  data: 0.000363  max mem: 1007\n","  [ 90/469]  eta: 0:00:19    time: 0.049906  data: 0.000335  max mem: 1007\n","  [100/469]  eta: 0:00:19    time: 0.049915  data: 0.000229  max mem: 1007\n","  [110/469]  eta: 0:00:18    time: 0.049917  data: 0.000392  max mem: 1007\n","  [120/469]  eta: 0:00:18    time: 0.049882  data: 0.000363  max mem: 1007\n","  [130/469]  eta: 0:00:17    time: 0.049876  data: 0.000230  max mem: 1007\n","  [140/469]  eta: 0:00:16    time: 0.049882  data: 0.000390  max mem: 1007\n","  [150/469]  eta: 0:00:16    time: 0.049889  data: 0.000401  max mem: 1007\n","  [160/469]  eta: 0:00:15    time: 0.049897  data: 0.000272  max mem: 1007\n","  [170/469]  eta: 0:00:15    time: 0.049889  data: 0.000260  max mem: 1007\n","  [180/469]  eta: 0:00:14    time: 0.049897  data: 0.000248  max mem: 1007\n","  [190/469]  eta: 0:00:14    time: 0.049905  data: 0.000245  max mem: 1007\n","  [200/469]  eta: 0:00:13    time: 0.049922  data: 0.000242  max mem: 1007\n","  [210/469]  eta: 0:00:13    time: 0.049939  data: 0.000246  max mem: 1007\n","  [220/469]  eta: 0:00:12    time: 0.049929  data: 0.000335  max mem: 1007\n","  [230/469]  eta: 0:00:12    time: 0.049928  data: 0.000322  max mem: 1007\n","  [240/469]  eta: 0:00:11    time: 0.049938  data: 0.000231  max mem: 1007\n","  [250/469]  eta: 0:00:11    time: 0.049928  data: 0.000205  max mem: 1007\n","  [260/469]  eta: 0:00:10    time: 0.049927  data: 0.000177  max mem: 1007\n","  [270/469]  eta: 0:00:10    time: 0.049926  data: 0.000225  max mem: 1007\n","  [280/469]  eta: 0:00:09    time: 0.049918  data: 0.000248  max mem: 1007\n","  [290/469]  eta: 0:00:09    time: 0.049923  data: 0.000237  max mem: 1007\n","  [300/469]  eta: 0:00:08    time: 0.049919  data: 0.000246  max mem: 1007\n","  [310/469]  eta: 0:00:08    time: 0.049901  data: 0.000245  max mem: 1007\n","  [320/469]  eta: 0:00:07    time: 0.049882  data: 0.000219  max mem: 1007\n","  [330/469]  eta: 0:00:07    time: 0.049887  data: 0.000225  max mem: 1007\n","  [340/469]  eta: 0:00:06    time: 0.049886  data: 0.000247  max mem: 1007\n","  [350/469]  eta: 0:00:06    time: 0.049894  data: 0.000251  max mem: 1007\n","  [360/469]  eta: 0:00:05    time: 0.049918  data: 0.000255  max mem: 1007\n","  [370/469]  eta: 0:00:05    time: 0.049919  data: 0.000246  max mem: 1007\n","  [380/469]  eta: 0:00:04    time: 0.049914  data: 0.000247  max mem: 1007\n","  [390/469]  eta: 0:00:03    time: 0.049917  data: 0.000260  max mem: 1007\n","  [400/469]  eta: 0:00:03    time: 0.049912  data: 0.000248  max mem: 1007\n","  [410/469]  eta: 0:00:02    time: 0.049901  data: 0.000247  max mem: 1007\n","  [420/469]  eta: 0:00:02    time: 0.049893  data: 0.000268  max mem: 1007\n","  [430/469]  eta: 0:00:01    time: 0.049892  data: 0.000250  max mem: 1007\n","  [440/469]  eta: 0:00:01    time: 0.049899  data: 0.000244  max mem: 1007\n","  [450/469]  eta: 0:00:00    time: 0.049908  data: 0.000243  max mem: 1007\n","  [460/469]  eta: 0:00:00    time: 0.049892  data: 0.000196  max mem: 1007\n","  [468/469]  eta: 0:00:00    time: 0.049900  data: 0.000179  max mem: 1007\n"," Total time: 0:00:23 (0.050985 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.0, Top5: 50.0\n","20-NN classifier result: Top1: 10.0, Top5: 50.001666666666665\n","100-NN classifier result: Top1: 9.996666666666666, Top5: 50.001666666666665\n","200-NN classifier result: Top1: 9.996666666666666, Top5: 49.99666666666667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLTfrtrNqKJM","executionInfo":{"status":"ok","timestamp":1623290787530,"user_tz":240,"elapsed":30991,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"f12ee67b-fdf9-4668-fb9c-b03201fc7ac2"},"source":["args={\"batch_size_per_gpu\": 128,\n","      \"nb_knn\": [10, 20, 100, 200], \n","      \"temperature\": 0.07,\n","      \"pretrained_weights\": './checkpoint0080.pth',\n","      \"use_cuda\": True,\n","      \"arch\": \"vit_tiny\",\n","      \"patch_size\": 4, \n","      \"checkpoint_key\": \"teacher\", \n","      \"dump_features\": None,\n","      \"load_features\": None, \n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\", \n","      \"local_rank\": 0, \n","      \"data_path\": './data/FashionMNIST'}\n","\n","class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self\n","\n","args=AttrDict(args)\n","\n","train_features, test_features, train_labels, test_labels = extract_feature_pipeline(args)\n","\n","if utils.get_rank() == 0:\n","    if args.use_cuda:\n","        train_features = train_features.cuda()\n","        test_features = test_features.cuda()\n","        train_labels = train_labels.cuda()\n","        test_labels = test_labels.cuda()\n","\n","    print(\"Features are ready!\\nStart the k-NN classification.\")\n","    for k in args.nb_knn:\n","        top1, top5 = knn_classifier(train_features, train_labels,\n","            test_features, test_labels, k, args.temperature)\n","        print(f\"{k}-NN classifier result: Top1: {top1}, Top5: {top5}\")\n","dist.barrier()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Data loaded with 10000 train and 60000 val imgs.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Model vit_tiny 4x4 built.\n","Take key teacher in provided checkpoint dict\n","Pretrained weights found at ./checkpoint0080.pth and loaded with msg: _IncompatibleKeys(missing_keys=[], unexpected_keys=['head.mlp.0.weight', 'head.mlp.0.bias', 'head.mlp.2.weight', 'head.mlp.2.bias', 'head.mlp.4.weight', 'head.mlp.4.bias', 'head.last_layer.weight_g', 'head.last_layer.weight_v'])\n","Extracting features for train set...\n","Storing features into tensor of shape torch.Size([10000, 192])\n","  [ 0/79]  eta: 0:00:34    time: 0.435320  data: 0.375431  max mem: 1007\n","  [10/79]  eta: 0:00:04    time: 0.070094  data: 0.034303  max mem: 1007\n","  [20/79]  eta: 0:00:03    time: 0.041756  data: 0.000174  max mem: 1007\n","  [30/79]  eta: 0:00:02    time: 0.049940  data: 0.000201  max mem: 1007\n","  [40/79]  eta: 0:00:02    time: 0.049932  data: 0.000279  max mem: 1007\n","  [50/79]  eta: 0:00:01    time: 0.049908  data: 0.000265  max mem: 1007\n","  [60/79]  eta: 0:00:01    time: 0.049895  data: 0.000196  max mem: 1007\n","  [70/79]  eta: 0:00:00    time: 0.049889  data: 0.000143  max mem: 1007\n","  [78/79]  eta: 0:00:00    time: 0.049999  data: 0.000113  max mem: 1007\n"," Total time: 0:00:04 (0.055591 s / it)\n","Extracting features for val set...\n","Storing features into tensor of shape torch.Size([60000, 192])\n","  [  0/469]  eta: 0:03:27    time: 0.443356  data: 0.365113  max mem: 1007\n","  [ 10/469]  eta: 0:00:32    time: 0.070825  data: 0.033379  max mem: 1007\n","  [ 20/469]  eta: 0:00:27    time: 0.041684  data: 0.000181  max mem: 1007\n","  [ 30/469]  eta: 0:00:25    time: 0.049835  data: 0.000357  max mem: 1007\n","  [ 40/469]  eta: 0:00:23    time: 0.049872  data: 0.000411  max mem: 1007\n","  [ 50/469]  eta: 0:00:22    time: 0.049883  data: 0.000249  max mem: 1007\n","  [ 60/469]  eta: 0:00:21    time: 0.049885  data: 0.000238  max mem: 1007\n","  [ 70/469]  eta: 0:00:21    time: 0.049888  data: 0.000247  max mem: 1007\n","  [ 80/469]  eta: 0:00:20    time: 0.049954  data: 0.000241  max mem: 1007\n","  [ 90/469]  eta: 0:00:19    time: 0.049969  data: 0.000234  max mem: 1007\n","  [100/469]  eta: 0:00:19    time: 0.049927  data: 0.000337  max mem: 1007\n","  [110/469]  eta: 0:00:18    time: 0.049912  data: 0.000351  max mem: 1007\n","  [120/469]  eta: 0:00:18    time: 0.049895  data: 0.000267  max mem: 1007\n","  [130/469]  eta: 0:00:17    time: 0.049880  data: 0.000277  max mem: 1007\n","  [140/469]  eta: 0:00:16    time: 0.049891  data: 0.000276  max mem: 1007\n","  [150/469]  eta: 0:00:16    time: 0.049900  data: 0.000416  max mem: 1007\n","  [160/469]  eta: 0:00:15    time: 0.049900  data: 0.000440  max mem: 1007\n","  [170/469]  eta: 0:00:15    time: 0.049906  data: 0.000283  max mem: 1007\n","  [180/469]  eta: 0:00:14    time: 0.049907  data: 0.000324  max mem: 1007\n","  [190/469]  eta: 0:00:14    time: 0.049899  data: 0.000324  max mem: 1007\n","  [200/469]  eta: 0:00:13    time: 0.049914  data: 0.000248  max mem: 1007\n","  [210/469]  eta: 0:00:13    time: 0.049932  data: 0.000253  max mem: 1007\n","  [220/469]  eta: 0:00:12    time: 0.049903  data: 0.000263  max mem: 1007\n","  [230/469]  eta: 0:00:12    time: 0.049861  data: 0.000270  max mem: 1007\n","  [240/469]  eta: 0:00:11    time: 0.049865  data: 0.000260  max mem: 1007\n","  [250/469]  eta: 0:00:11    time: 0.049889  data: 0.000235  max mem: 1007\n","  [260/469]  eta: 0:00:10    time: 0.049902  data: 0.000282  max mem: 1007\n","  [270/469]  eta: 0:00:10    time: 0.049904  data: 0.000380  max mem: 1007\n","  [280/469]  eta: 0:00:09    time: 0.049908  data: 0.000443  max mem: 1007\n","  [290/469]  eta: 0:00:09    time: 0.049912  data: 0.000353  max mem: 1007\n","  [300/469]  eta: 0:00:08    time: 0.049910  data: 0.000250  max mem: 1007\n","  [310/469]  eta: 0:00:08    time: 0.049879  data: 0.000214  max mem: 1007\n","  [320/469]  eta: 0:00:07    time: 0.049878  data: 0.000172  max mem: 1007\n","  [330/469]  eta: 0:00:07    time: 0.049920  data: 0.000176  max mem: 1007\n","  [340/469]  eta: 0:00:06    time: 0.049919  data: 0.000220  max mem: 1007\n","  [350/469]  eta: 0:00:06    time: 0.049902  data: 0.000261  max mem: 1007\n","  [360/469]  eta: 0:00:05    time: 0.049896  data: 0.000244  max mem: 1007\n","  [370/469]  eta: 0:00:05    time: 0.049897  data: 0.000235  max mem: 1007\n","  [380/469]  eta: 0:00:04    time: 0.049888  data: 0.000242  max mem: 1007\n","  [390/469]  eta: 0:00:03    time: 0.049888  data: 0.000240  max mem: 1007\n","  [400/469]  eta: 0:00:03    time: 0.049883  data: 0.000247  max mem: 1007\n","  [410/469]  eta: 0:00:02    time: 0.049890  data: 0.000372  max mem: 1007\n","  [420/469]  eta: 0:00:02    time: 0.049859  data: 0.000329  max mem: 1007\n","  [430/469]  eta: 0:00:01    time: 0.049862  data: 0.000217  max mem: 1007\n","  [440/469]  eta: 0:00:01    time: 0.049915  data: 0.000271  max mem: 1007\n","  [450/469]  eta: 0:00:00    time: 0.049901  data: 0.000372  max mem: 1007\n","  [460/469]  eta: 0:00:00    time: 0.049892  data: 0.000290  max mem: 1007\n","  [468/469]  eta: 0:00:00    time: 0.049906  data: 0.000149  max mem: 1007\n"," Total time: 0:00:23 (0.050946 s / it)\n","Features are ready!\n","Start the k-NN classification.\n","10-NN classifier result: Top1: 10.0, Top5: 50.0\n","20-NN classifier result: Top1: 10.0, Top5: 50.001666666666665\n","100-NN classifier result: Top1: 9.996666666666666, Top5: 50.0\n","200-NN classifier result: Top1: 9.996666666666666, Top5: 49.99666666666667\n"],"name":"stdout"}]}]}
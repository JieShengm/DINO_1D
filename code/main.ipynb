{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Copy of v2_main.ipynb","provenance":[{"file_id":"1kEVWoRQMkE46_iYm80cFpkTEzwwKjog6","timestamp":1624418088692}],"collapsed_sections":[],"mount_file_id":"1f7vYImqGxZogyfShQeAI1cKERxS2pFb6","authorship_tag":"ABX9TyPmUNXz6STW5Zz+ItCNGLCK"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":37},"id":"GfD9KXe-jfHK","executionInfo":{"status":"ok","timestamp":1624628830103,"user_tz":240,"elapsed":204,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"4422beff-9fd2-4236-e932-f70403cf4ed7"},"source":["import os\n","os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"H6n7n40akKRK"},"source":["os.chdir('/content/drive/MyDrive/dino/v4_0623')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jmPXTYQmkWGb"},"source":["import argparse\n","import os\n","import sys\n","import datetime\n","import time\n","import math\n","import json\n","from pathlib import Path\n","\n","import numpy as np\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.distributed as dist\n","import torch.backends.cudnn as cudnn\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torchvision import models as torchvision_models\n","\n","import utils\n","import vision_transformer as vits\n","from vision_transformer import DINOHead\n","\n","\n","torchvision_archs = sorted(name for name in torchvision_models.__dict__\n","    if name.islower() and not name.startswith(\"__\")\n","    and callable(torchvision_models.__dict__[name]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QkDN9tSos6mU"},"source":["class AttrDict(dict):\n","    def __init__(self, *args, **kwargs):\n","        super(AttrDict, self).__init__(*args, **kwargs)\n","        self.__dict__ = self"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RBxzW961kY1K"},"source":["args={\"arch\": 'vit_tiny',\n","      \"patch_size\": 4,\n","      \"out_dim\": 30,\n","      \"norm_last_layer\": True,\n","      \"momentum_teacher\": 0.996,\n","      \"use_bn_in_head\": False,\n","    \n","      # Temperature teacher parameters\n","      \"warmup_teacher_temp\": 0.04,\n","      \"teacher_temp\": 0.04,\n","      \"warmup_teacher_temp_epochs\": 0,\n","    \n","      # Training/Optimization parameters\n","      \"use_fp16\": True,\n","      \"weight_decay\": 0.04,\n","      \"weight_decay_end\": 0.4,\n","      \"clip_grad\": 3.0,\n","      \"batch_size_per_gpu\": 32,\n","      \"epochs\": 100,\n","      \"freeze_last_layer\": 1,\n","      \"lr\": 0.0005,\n","      \"warmup_epochs\": 10,\n","      \"min_lr\": 1e-6,\n","      \"optimizer\": 'adamw',\n","    \n","      # Multi-crop parameters\n","      \"global_crops_scale\": 400,\n","      \"local_crops_number\": 8,\n","      \"local_crops_scale\": 80,\n","\n","      # Misc\n","      \"data_path\": '../data',\n","      \"dataset\": 'FashionMNIST',\n","      \"output_dir\": \"./v4_result\",\n","      \"saveckp_freq\": 5,\n","      \"seed\": 0,\n","      \"num_workers\": 10,\n","      \"dist_url\": \"env://\",\n","      \"local_rank\": 0}\n","\n","\n","\n","args=AttrDict(args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LOkJ4e_dkbuj"},"source":["def train_dino(args):\n","    utils.init_distributed_mode(args)\n","    utils.fix_random_seeds(args.seed)\n","    print(\"git:\\n  {}\\n\".format(utils.get_sha()))\n","    print(\"\\n\".join(\"%s: %s\" % (k, str(v)) for k, v in sorted(dict(vars(args)).items())))\n","    cudnn.benchmark = True\n","\n","    # ============ preparing data ... ============\n","    transform = DataAugmentationDINO(\n","        args.global_crops_scale,\n","        args.local_crops_scale,\n","        args.local_crops_number,\n","    )\n","    if(args.dataset == \"FashionMNIST\"):\n","      dataset = datasets.FashionMNIST(args.data_path, download=True, train=True, transform=transform)\n","      #X_train = torch.flatten(dataset.data, start_dim=1).numpy()\n","      #y_train = dataset.targets.numpy()\n","      #dataset = CustomDataset(X_train, y_train)\n","      #dataset_trans = DataAugmentationDINO(dataset, args.global_crops_scale, args.local_crops_scale, args.local_crops_number)\n","      sampler = torch.utils.data.DistributedSampler(dataset, shuffle=True)\n","      data_loader = torch.utils.data.DataLoader(\n","          dataset,\n","          sampler=sampler,\n","          batch_size=args.batch_size_per_gpu,\n","          num_workers=args.num_workers,\n","          pin_memory=True,\n","          drop_last=True,\n","          )\n","    else:\n","      dataset = datasets.ImageFolder(args.data_path, transform=transform)\n","      sampler = torch.utils.data.DistributedSampler(dataset, shuffle=True)\n","      data_loader = torch.utils.data.DataLoader(\n","          dataset,\n","          sampler=sampler,\n","          batch_size=args.batch_size_per_gpu,\n","          num_workers=args.num_workers,\n","          pin_memory=True,\n","          drop_last=True,\n","          )\n","      \n","    print(f\"Data loaded: there are {len(dataset)} images.\")\n","\n","    # ============ building student and teacher networks ... ============\n","    # we changed the name DeiT-S for ViT-S to avoid confusions\n","    args.arch = args.arch.replace(\"deit\", \"vit\")\n","    # if the network is a vision transformer (i.e. vit_tiny, vit_small, vit_base)\n","    if args.arch in vits.__dict__.keys():\n","        student = vits.__dict__[args.arch](\n","            patch_size=args.patch_size,\n","            drop_path_rate=0.1,  # stochastic depth\n","        )\n","        teacher = vits.__dict__[args.arch](patch_size=args.patch_size)\n","        embed_dim = student.embed_dim\n","    # otherwise, we check if the architecture is in torchvision models\n","    elif args.arch in torchvision_models.__dict__.keys():\n","        student = torchvision_models.__dict__[args.arch]()\n","        teacher = torchvision_models.__dict__[args.arch]()\n","        embed_dim = student.fc.weight.shape[1]\n","    else:\n","        print(f\"Unknow architecture: {args.arch}\")\n","\n","    # multi-crop wrapper handles forward with inputs of different resolutions\n","    student = utils.MultiCropWrapper(student, DINOHead(\n","        embed_dim,\n","        args.out_dim,\n","        use_bn=args.use_bn_in_head,\n","        norm_last_layer=args.norm_last_layer,\n","    ))\n","    teacher = utils.MultiCropWrapper(\n","        teacher,\n","        DINOHead(embed_dim, args.out_dim, args.use_bn_in_head),\n","    )\n","    # move networks to gpu\n","    student, teacher = student.cuda(), teacher.cuda()\n","    # synchronize batch norms (if any)\n","    if utils.has_batchnorms(student):\n","        student = nn.SyncBatchNorm.convert_sync_batchnorm(student)\n","        teacher = nn.SyncBatchNorm.convert_sync_batchnorm(teacher)\n","\n","        # we need DDP wrapper to have synchro batch norms working...\n","        teacher = nn.parallel.DistributedDataParallel(teacher, device_ids=[args.gpu],find_unused_parameters=True)\n","        teacher_without_ddp = teacher.module\n","    else:\n","        # teacher_without_ddp and teacher are the same thing\n","        teacher_without_ddp = teacher\n","    student = nn.parallel.DistributedDataParallel(student, device_ids=[args.gpu],find_unused_parameters=True)\n","    # teacher and student start with the same weights\n","    teacher_without_ddp.load_state_dict(student.module.state_dict())\n","    # there is no backpropagation through the teacher, so no need for gradients\n","    for p in teacher.parameters():\n","        p.requires_grad = False\n","    print(f\"Student and Teacher are built: they are both {args.arch} network.\")\n","\n","    # ============ preparing loss ... ============\n","    dino_loss = DINOLoss(\n","        args.out_dim,\n","        args.local_crops_number + 2,  # total number of crops = 2 global crops + local_crops_number\n","        args.warmup_teacher_temp,\n","        args.teacher_temp,\n","        args.warmup_teacher_temp_epochs,\n","        args.epochs,\n","    ).cuda()\n","\n","    # ============ preparing optimizer ... ============\n","    params_groups = utils.get_params_groups(student)\n","    if args.optimizer == \"adamw\":\n","        optimizer = torch.optim.AdamW(params_groups)  # to use with ViTs\n","    elif args.optimizer == \"sgd\":\n","        optimizer = torch.optim.SGD(params_groups, lr=0, momentum=0.9)  # lr is set by scheduler\n","    elif args.optimizer == \"lars\":\n","        optimizer = utils.LARS(params_groups)  # to use with convnet and large batches\n","    # for mixed precision training\n","    fp16_scaler = None\n","    if args.use_fp16:\n","        fp16_scaler = torch.cuda.amp.GradScaler()\n","\n","    # ============ init schedulers ... ============\n","    lr_schedule = utils.cosine_scheduler(\n","        args.lr * (args.batch_size_per_gpu * utils.get_world_size()) / 256.,  # linear scaling rule\n","        args.min_lr,\n","        args.epochs, len(data_loader),\n","        warmup_epochs=args.warmup_epochs,\n","    )\n","    wd_schedule = utils.cosine_scheduler(\n","        args.weight_decay,\n","        args.weight_decay_end,\n","        args.epochs, len(data_loader),\n","    )\n","    # momentum parameter is increased to 1. during training with a cosine schedule\n","    momentum_schedule = utils.cosine_scheduler(args.momentum_teacher, 1,\n","                                               args.epochs, len(data_loader))\n","    print(f\"Loss, optimizer and schedulers ready.\")\n","\n","    # ============ optionally resume training ... ============\n","    to_restore = {\"epoch\": 0}\n","    utils.restart_from_checkpoint(\n","        os.path.join(args.output_dir, \"checkpoint.pth\"),\n","        run_variables=to_restore,\n","        student=student,\n","        teacher=teacher,\n","        optimizer=optimizer,\n","        fp16_scaler=fp16_scaler,\n","        dino_loss=dino_loss,\n","    )\n","    start_epoch = to_restore[\"epoch\"]\n","\n","    start_time = time.time()\n","    print(\"Starting DINO training !\")\n","    for epoch in range(start_epoch, args.epochs):\n","        data_loader.sampler.set_epoch(epoch)\n","\n","        # ============ training one epoch of DINO ... ============\n","        train_stats = train_one_epoch(student, teacher, teacher_without_ddp, dino_loss,\n","            data_loader, optimizer, lr_schedule, wd_schedule, momentum_schedule,\n","            epoch, fp16_scaler, args)\n","\n","        # ============ writing logs ... ============\n","        save_dict = {\n","            'student': student.state_dict(),\n","            'teacher': teacher.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'epoch': epoch + 1,\n","            'args': args,\n","            'dino_loss': dino_loss.state_dict(),\n","        }\n","        if fp16_scaler is not None:\n","            save_dict['fp16_scaler'] = fp16_scaler.state_dict()\n","        utils.save_on_master(save_dict, os.path.join(args.output_dir, 'checkpoint.pth'))\n","        if args.saveckp_freq and epoch % args.saveckp_freq == 0:\n","            utils.save_on_master(save_dict, os.path.join(args.output_dir, f'checkpoint{epoch:04}.pth'))\n","        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n","                     'epoch': epoch}\n","        if utils.is_main_process():\n","            with (Path(args.output_dir) / \"log.txt\").open(\"a\") as f:\n","                f.write(json.dumps(log_stats) + \"\\n\")\n","    total_time = time.time() - start_time\n","    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n","    print('Training time {}'.format(total_time_str))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WYXX5BQ3k-Iy"},"source":["def train_one_epoch(student, teacher, teacher_without_ddp, dino_loss, data_loader,\n","                    optimizer, lr_schedule, wd_schedule, momentum_schedule,epoch,\n","                    fp16_scaler, args):\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    header = 'Epoch: [{}/{}]'.format(epoch, args.epochs)\n","    for it, (images, _) in enumerate(metric_logger.log_every(data_loader, 10, header)):\n","        # update weight decay and learning rate according to their schedule\n","        it = len(data_loader) * epoch + it  # global training iteration\n","        for i, param_group in enumerate(optimizer.param_groups):\n","            param_group[\"lr\"] = lr_schedule[it]\n","            if i == 0:  # only the first group is regularized\n","                param_group[\"weight_decay\"] = wd_schedule[it]\n","\n","        # move images to gpu\n","        images = [im.cuda(non_blocking=True) for im in images]\n","        # teacher and student forward passes + compute dino loss\n","        with torch.cuda.amp.autocast(fp16_scaler is not None):\n","            teacher_output = teacher(images[:2])  # only the 2 global views pass through the teacher\n","            student_output = student(images)\n","            loss = dino_loss(student_output, teacher_output, epoch)\n","\n","        if not math.isfinite(loss.item()):\n","            print(\"Loss is {}, stopping training\".format(loss.item()), force=True)\n","            sys.exit(1)\n","\n","        # student update\n","        optimizer.zero_grad()\n","        param_norms = None\n","        if fp16_scaler is None:\n","            loss.backward()\n","            if args.clip_grad:\n","                param_norms = utils.clip_gradients(student, args.clip_grad)\n","            utils.cancel_gradients_last_layer(epoch, student,\n","                                              args.freeze_last_layer)\n","            optimizer.step()\n","        else:\n","            fp16_scaler.scale(loss).backward()\n","            if args.clip_grad:\n","                fp16_scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params in-place\n","                param_norms = utils.clip_gradients(student, args.clip_grad)\n","            utils.cancel_gradients_last_layer(epoch, student,\n","                                              args.freeze_last_layer)\n","            fp16_scaler.step(optimizer)\n","            fp16_scaler.update()\n","\n","        # EMA update for the teacher\n","        with torch.no_grad():\n","            m = momentum_schedule[it]  # momentum parameter\n","            for param_q, param_k in zip(student.module.parameters(), teacher_without_ddp.parameters()):\n","                param_k.data.mul_(m).add_((1 - m) * param_q.detach().data)\n","\n","        # logging\n","        torch.cuda.synchronize()\n","        metric_logger.update(loss=loss.item())\n","        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n","        metric_logger.update(wd=optimizer.param_groups[0][\"weight_decay\"])\n","    # gather the stats from all processes\n","    metric_logger.synchronize_between_processes()\n","    print(\"Averaged stats:\", metric_logger)\n","    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7o6IwkyylBHn"},"source":["class DINOLoss(nn.Module):\n","    def __init__(self, out_dim, ncrops, warmup_teacher_temp, teacher_temp,\n","                 warmup_teacher_temp_epochs, nepochs, student_temp=0.1,\n","                 center_momentum=0.9):\n","        super().__init__()\n","        self.student_temp = student_temp\n","        self.center_momentum = center_momentum\n","        self.ncrops = ncrops\n","        self.register_buffer(\"center\", torch.zeros(1, out_dim))\n","        # we apply a warm up for the teacher temperature because\n","        # a too high temperature makes the training instable at the beginning\n","        self.teacher_temp_schedule = np.concatenate((\n","            np.linspace(warmup_teacher_temp,\n","                        teacher_temp, warmup_teacher_temp_epochs),\n","            np.ones(nepochs - warmup_teacher_temp_epochs) * teacher_temp\n","        ))\n","\n","    def forward(self, student_output, teacher_output, epoch):\n","        \"\"\"\n","        Cross-entropy between softmax outputs of the teacher and student networks.\n","        \"\"\"\n","        student_out = student_output / self.student_temp\n","        student_out = student_out.chunk(self.ncrops)\n","\n","        # teacher centering and sharpening\n","        temp = self.teacher_temp_schedule[epoch]\n","        teacher_out = F.softmax((teacher_output - self.center) / temp, dim=-1)\n","        teacher_out = teacher_out.detach().chunk(2)\n","\n","        total_loss = 0\n","        n_loss_terms = 0\n","        for iq, q in enumerate(teacher_out):\n","            for v in range(len(student_out)):\n","                if v == iq:\n","                    # we skip cases where student and teacher operate on the same view\n","                    continue\n","                loss = torch.sum(-q * F.log_softmax(student_out[v], dim=-1), dim=-1)\n","                total_loss += loss.mean()\n","                n_loss_terms += 1\n","        total_loss /= n_loss_terms\n","        self.update_center(teacher_output)\n","        return total_loss\n","\n","    @torch.no_grad()\n","    def update_center(self, teacher_output):\n","        \"\"\"\n","        Update center used for teacher output.\n","        \"\"\"\n","        batch_center = torch.sum(teacher_output, dim=0, keepdim=True)\n","        dist.all_reduce(batch_center)\n","        batch_center = batch_center / (len(teacher_output) * dist.get_world_size())\n","\n","        # ema update\n","        self.center = self.center * self.center_momentum + batch_center * (1 - self.center_momentum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uIDBoIakmfeA"},"source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, images, labels=None, transforms=None):\n","        self.X = images\n","        self.y = labels\n","        self.transforms = transforms\n","         \n","    def __len__(self):\n","        return (len(self.X))\n","    \n","    def __getitem__(self, i):\n","        data = self.X[i]\n","        #data = np.asarray(data).astype(np.float32).reshape(1,self.X[i].shape[0])\n","\n","        if self.transforms:\n","            data = self.transforms(data)\n","            \n","        if self.y is not None:\n","            return (data, self.y[i])\n","        else:\n","            return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKvSpq1Iml6j"},"source":["class RandomSelect1D(object):\n","  # Here scale is a range to choose from\n","  def __init__(self, crops_scale):\n","    self.scale = crops_scale\n","\n","  def __call__(self, vec):\n","    length = 784\n","    # Get the first random scale\n","    idx = np.random.choice(length,size=(length-self.scale),replace=False)\n","    vec[idx] = 0\n","    return vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XRIxoOrPlElo"},"source":["class DataAugmentationDINO(object):\n","    def __init__(self, global_crops_scale, local_crops_scale, local_crops_number):\n","#        flip_and_color_jitter = transforms.Compose([\n","#            transforms.RandomHorizontalFlip(p=0.5),\n","#            transforms.RandomApply(\n","#                [transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1)],\n","#                p=0.8\n","#            ),\n","#            transforms.RandomGrayscale(p=0.2),\n","#        ])\n","#        normalize = transforms.Compose([\n","#            transforms.ToTensor(),\n","#            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","#        ])\n","#\n","        # first global crop\n","        self.global_transfo1 = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Lambda(lambda x: torch.flatten(x)),\n","            RandomSelect1D(global_crops_scale),\n","        ])\n","        # second global crop\n","        self.global_transfo2 = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Lambda(lambda x: torch.flatten(x)),\n","            RandomSelect1D(global_crops_scale),\n","        ])\n","        # transformation for the local small crops\n","        self.local_crops_number = local_crops_number\n","        self.local_transfo = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Lambda(lambda x: torch.flatten(x)),\n","            RandomSelect1D(global_crops_scale),\n","        ])\n","\n","    def __call__(self, image):\n","        crops = []\n","        crops.append(self.global_transfo1(image))\n","        crops.append(self.global_transfo2(image))\n","        for _ in range(self.local_crops_number):\n","            crops.append(self.local_transfo(image))\n","        return crops"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":358},"id":"4FS2Ayi0lNC4","executionInfo":{"status":"error","timestamp":1624628843292,"user_tz":240,"elapsed":8888,"user":{"displayName":"Jie Sheng","photoUrl":"","userId":"00636302776241690510"}},"outputId":"3098a06d-4f63-4d0b-d465-970df5dd9d76"},"source":["Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n","pp=train_dino(args)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Will run the code on one GPU.\n","| distributed init (rank 0): env://\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-18baaad216e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dino\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-19f49405fc80>\u001b[0m in \u001b[0;36mtrain_dino\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_distributed_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_random_seeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"git:\\n  {}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/dino/v4_0623/utils.py\u001b[0m in \u001b[0;36mget_sha\u001b[0;34m()\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mbranch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N/A'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0msha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'git'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rev-parse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HEAD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'git'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'git'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'diff-index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HEAD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/dino/v4_0623/utils.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(command)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m     \u001b[0msha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'N/A'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"clean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 411\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    949\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}